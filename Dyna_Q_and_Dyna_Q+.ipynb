{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talgiladi/reinforcement-learning/blob/main/Dyna_Q_and_Dyna_Q%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "456971b7c32e2bf5364ff3e844755588",
          "grade": false,
          "grade_id": "cell-2379d0e980554734",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_F8hDrNiOTZ0"
      },
      "source": [
        "# Assignment: Dyna-Q and Dyna-Q+"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "76de530741f980cceea89c1cbca751b3",
          "grade": false,
          "grade_id": "cell-e4a73a1d4819583b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7rAKbHIiOTZ8"
      },
      "source": [
        "Welcome to this programming assignment! In this notebook, you will:\n",
        "1. implement the Dyna-Q and Dyna-Q+ algorithms.\n",
        "2. compare their performance on an environment which changes to become 'better' than it was before, that is, the task becomes easier.\n",
        "\n",
        "We will give you the environment and infrastructure to run the experiment and visualize the performance. The assignment will be graded automatically by comparing the behavior of your agent to our implementations of the algorithms. The random seed will be set explicitly to avoid different behaviors due to randomness.\n",
        "\n",
        "Please go through the cells in order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b5700a0fc8aa27a9871262534a74584d",
          "grade": false,
          "grade_id": "cell-fc7a8bce812462f8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "v33615gPOTZ8"
      },
      "source": [
        "## The Shortcut Maze Environment\n",
        "\n",
        "In this maze environment, the goal is to reach the goal state (G) as fast as possible from the starting state (S). There are four actions â€“ up, down, right, left â€“ which take the agent deterministically from a state to the corresponding neighboring states, except when movement is blocked by a wall (denoted by grey) or the edge of the maze, in which case the agent remains where it is. The reward is +1 on reaching the goal state, 0 otherwise. On reaching the goal state G, the agent returns to the start state S to being a new episode. This is a discounted, episodic task with $\\gamma = 0.95$.\n",
        "\n",
        "<img src=\"./images/shortcut_env.png\" alt=\"environment\" width=\"400\"/>\n",
        "\n",
        "Later in the assignment, we will use a variant of this maze in which a 'shortcut' opens up after a certain number of timesteps. We will test if the the Dyna-Q and Dyna-Q+ agents are able to find the newly-opened shorter route to the goal state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b5d6eca06a34b6a6e873658478461b95",
          "grade": false,
          "grade_id": "cell-003d45ed0386900a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BfQFOyceOTZ9"
      },
      "source": [
        "## Packages\n",
        "\n",
        "We import the following libraries that are required for this assignment. Primarily, we shall be using the following libraries:\n",
        "1. numpy: the fundamental package for scientific computing with Python.\n",
        "2. matplotlib: the library for plotting graphs in Python.\n",
        "3. RL-Glue: the library for reinforcement learning experiments.\n",
        "\n",
        "**Please do not import other libraries** as this will break the autograder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "120eb20b7f1dddd120d76b2aa7919153",
          "grade": false,
          "grade_id": "cell-bee88a7e78d66006",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJqf3DQHOTZ9",
        "outputId": "8834445a-008e-49dd-c592-4b062809ec99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jdc\n",
            "  Downloading jdc-0.0.9-py2.py3-none-any.whl.metadata (817 bytes)\n",
            "Downloading jdc-0.0.9-py2.py3-none-any.whl (2.1 kB)\n",
            "Installing collected packages: jdc\n",
            "Successfully installed jdc-0.0.9\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "%pip install jdc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import jdc\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#!/usr/bin/env python\n",
        "\n",
        "\"\"\"Glues together an experiment, agent, and environment.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "class RLGlue:\n",
        "    \"\"\"RLGlue class\n",
        "\n",
        "    args:\n",
        "        env_name (string): the name of the module where the Environment class can be found\n",
        "        agent_name (string): the name of the module where the Agent class can be found\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env_class, agent_class):\n",
        "        self.environment = env_class()\n",
        "        self.agent = agent_class()\n",
        "\n",
        "        self.total_reward = None\n",
        "        self.last_action = None\n",
        "        self.num_steps = None\n",
        "        self.num_episodes = None\n",
        "\n",
        "    def rl_init(self, agent_init_info={}, env_init_info={}):\n",
        "        \"\"\"Initial method called when RLGlue experiment is created\"\"\"\n",
        "        self.environment.env_init(env_init_info)\n",
        "        self.agent.agent_init(agent_init_info)\n",
        "\n",
        "        self.total_reward = 0.0\n",
        "        self.num_steps = 0\n",
        "        self.num_episodes = 0\n",
        "\n",
        "    def rl_start(self, agent_start_info={}, env_start_info={}):\n",
        "        \"\"\"Starts RLGlue experiment\n",
        "\n",
        "        Returns:\n",
        "            tuple: (state, action)\n",
        "        \"\"\"\n",
        "\n",
        "        last_state = self.environment.env_start()\n",
        "        self.last_action = self.agent.agent_start(last_state)\n",
        "\n",
        "        observation = (last_state, self.last_action)\n",
        "\n",
        "        return observation\n",
        "\n",
        "    def rl_agent_start(self, observation):\n",
        "        \"\"\"Starts the agent.\n",
        "\n",
        "        Args:\n",
        "            observation: The first observation from the environment\n",
        "\n",
        "        Returns:\n",
        "            The action taken by the agent.\n",
        "        \"\"\"\n",
        "        return self.agent.agent_start(observation)\n",
        "\n",
        "    def rl_agent_step(self, reward, observation):\n",
        "        \"\"\"Step taken by the agent\n",
        "\n",
        "        Args:\n",
        "            reward (float): the last reward the agent received for taking the\n",
        "                last action.\n",
        "            observation : the state observation the agent receives from the\n",
        "                environment.\n",
        "\n",
        "        Returns:\n",
        "            The action taken by the agent.\n",
        "        \"\"\"\n",
        "        return self.agent.agent_step(reward, observation)\n",
        "\n",
        "    def rl_agent_end(self, reward):\n",
        "        \"\"\"Run when the agent terminates\n",
        "\n",
        "        Args:\n",
        "            reward (float): the reward the agent received when terminating\n",
        "        \"\"\"\n",
        "        self.agent.agent_end(reward)\n",
        "\n",
        "    def rl_env_start(self):\n",
        "        \"\"\"Starts RL-Glue environment.\n",
        "\n",
        "        Returns:\n",
        "            (float, state, Boolean): reward, state observation, boolean\n",
        "                indicating termination\n",
        "        \"\"\"\n",
        "        self.total_reward = 0.0\n",
        "        self.num_steps = 1\n",
        "\n",
        "        this_observation = self.environment.env_start()\n",
        "\n",
        "        return this_observation\n",
        "\n",
        "    def rl_env_step(self, action):\n",
        "        \"\"\"Step taken by the environment based on action from agent\n",
        "\n",
        "        Args:\n",
        "            action: Action taken by agent.\n",
        "\n",
        "        Returns:\n",
        "            (float, state, Boolean): reward, state observation, boolean\n",
        "                indicating termination.\n",
        "        \"\"\"\n",
        "        ro = self.environment.env_step(action)\n",
        "        (this_reward, _, terminal) = ro\n",
        "\n",
        "        self.total_reward += this_reward\n",
        "\n",
        "        if terminal:\n",
        "            self.num_episodes += 1\n",
        "        else:\n",
        "            self.num_steps += 1\n",
        "\n",
        "        return ro\n",
        "\n",
        "    def rl_step(self):\n",
        "        \"\"\"Step taken by RLGlue, takes environment step and either step or\n",
        "            end by agent.\n",
        "\n",
        "        Returns:\n",
        "            (float, state, action, Boolean): reward, last state observation,\n",
        "                last action, boolean indicating termination\n",
        "        \"\"\"\n",
        "\n",
        "        (reward, last_state, term) = self.environment.env_step(self.last_action)\n",
        "\n",
        "        self.total_reward += reward\n",
        "\n",
        "        if term:\n",
        "            self.num_episodes += 1\n",
        "            self.agent.agent_end(reward)\n",
        "            roat = (reward, last_state, None, term)\n",
        "        else:\n",
        "            self.num_steps += 1\n",
        "            self.last_action = self.agent.agent_step(reward, last_state)\n",
        "            roat = (reward, last_state, self.last_action, term)\n",
        "\n",
        "        return roat\n",
        "\n",
        "    def rl_cleanup(self):\n",
        "        \"\"\"Cleanup done at end of experiment.\"\"\"\n",
        "        self.environment.env_cleanup()\n",
        "        self.agent.agent_cleanup()\n",
        "\n",
        "    def rl_agent_message(self, message):\n",
        "        \"\"\"Message passed to communicate with agent during experiment\n",
        "\n",
        "        Args:\n",
        "            message: the message (or question) to send to the agent\n",
        "\n",
        "        Returns:\n",
        "            The message back (or answer) from the agent\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        return self.agent.agent_message(message)\n",
        "\n",
        "    def rl_env_message(self, message):\n",
        "        \"\"\"Message passed to communicate with environment during experiment\n",
        "\n",
        "        Args:\n",
        "            message: the message (or question) to send to the environment\n",
        "\n",
        "        Returns:\n",
        "            The message back (or answer) from the environment\n",
        "\n",
        "        \"\"\"\n",
        "        return self.environment.env_message(message)\n",
        "\n",
        "    def rl_episode(self, max_steps_this_episode):\n",
        "        \"\"\"Runs an RLGlue episode\n",
        "\n",
        "        Args:\n",
        "            max_steps_this_episode (Int): the maximum steps for the experiment to run in an episode\n",
        "\n",
        "        Returns:\n",
        "            Boolean: if the episode should terminate\n",
        "        \"\"\"\n",
        "        is_terminal = False\n",
        "\n",
        "        self.rl_start()\n",
        "        num_steps = 0\n",
        "\n",
        "        while (not is_terminal) and ((max_steps_this_episode == 0) or\n",
        "                                     (self.num_steps < max_steps_this_episode)):\n",
        "            rl_step_result = self.rl_step()\n",
        "            is_terminal = rl_step_result[3]\n",
        "\n",
        "        return is_terminal\n",
        "\n",
        "    def rl_return(self):\n",
        "        \"\"\"The total reward\n",
        "\n",
        "        Returns:\n",
        "            float: the total reward\n",
        "        \"\"\"\n",
        "        return self.total_reward\n",
        "\n",
        "    def rl_num_steps(self):\n",
        "        \"\"\"The total number of steps taken\n",
        "\n",
        "        Returns:\n",
        "            Int: the total number of steps taken\n",
        "        \"\"\"\n",
        "        return self.num_steps\n",
        "\n",
        "    def rl_num_episodes(self):\n",
        "        \"\"\"The number of episodes\n",
        "\n",
        "        Returns\n",
        "            Int: the total number of episodes\n",
        "\n",
        "        \"\"\"\n",
        "        return self.num_episodes\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UsdHxyJ-Ofhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#!/usr/bin/env python\n",
        "\n",
        "\"\"\"An abstract class that specifies the Agent API for RL-Glue-py.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "from abc import ABCMeta, abstractmethod\n",
        "\n",
        "\n",
        "class BaseAgent:\n",
        "    \"\"\"Implements the agent for an RL-Glue environment.\n",
        "    Note:\n",
        "        agent_init, agent_start, agent_step, agent_end, agent_cleanup, and\n",
        "        agent_message are required methods.\n",
        "    \"\"\"\n",
        "\n",
        "    __metaclass__ = ABCMeta\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def agent_init(self, agent_info):\n",
        "        \"\"\"Setup for the agent called when the experiment first starts.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def agent_start(self, observation):\n",
        "        \"\"\"The first method called when the experiment starts, called after\n",
        "        the environment starts.\n",
        "        Args:\n",
        "            observation (Numpy array): the state observation from the environment's evn_start function.\n",
        "        Returns:\n",
        "            The first action the agent takes.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def agent_step(self, reward, observation):\n",
        "        \"\"\"A step taken by the agent.\n",
        "        Args:\n",
        "            reward (float): the reward received for taking the last action taken\n",
        "            observation (Numpy array): the state observation from the\n",
        "                environment's step based, where the agent ended up after the\n",
        "                last step\n",
        "        Returns:\n",
        "            The action the agent is taking.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def agent_end(self, reward):\n",
        "        \"\"\"Run when the agent terminates.\n",
        "        Args:\n",
        "            reward (float): the reward the agent received for entering the terminal state.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def agent_cleanup(self):\n",
        "        \"\"\"Cleanup done after the agent ends.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def agent_message(self, message):\n",
        "        \"\"\"A function used to pass information from the agent to the experiment.\n",
        "        Args:\n",
        "            message: The message passed to the agent.\n",
        "        Returns:\n",
        "            The response (or answer) to the message.\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YnSa9eM9Obhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#!/usr/bin/env python\n",
        "#!/usr/bin/env python\n",
        "\n",
        "\"\"\"Abstract environment base class for RL-Glue-py.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from abc import ABCMeta, abstractmethod\n",
        "\n",
        "\n",
        "class BaseEnvironment:\n",
        "    \"\"\"Implements the environment for an RLGlue environment\n",
        "\n",
        "    Note:\n",
        "        env_init, env_start, env_step, env_cleanup, and env_message are required\n",
        "        methods.\n",
        "    \"\"\"\n",
        "\n",
        "    __metaclass__ = ABCMeta\n",
        "\n",
        "    def __init__(self):\n",
        "        reward = None\n",
        "        observation = None\n",
        "        termination = None\n",
        "        self.reward_obs_term = (reward, observation, termination)\n",
        "\n",
        "    @abstractmethod\n",
        "    def env_init(self, env_info={}):\n",
        "        \"\"\"Setup for the environment called when the experiment first starts.\n",
        "\n",
        "        Note:\n",
        "            Initialize a tuple with the reward, first state observation, boolean\n",
        "            indicating if it's terminal.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def env_start(self):\n",
        "        \"\"\"The first method called when the experiment starts, called before the\n",
        "        agent starts.\n",
        "\n",
        "        Returns:\n",
        "            The first state observation from the environment.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def env_step(self, action):\n",
        "        \"\"\"A step taken by the environment.\n",
        "\n",
        "        Args:\n",
        "            action: The action taken by the agent\n",
        "\n",
        "        Returns:\n",
        "            (float, state, Boolean): a tuple of the reward, state observation,\n",
        "                and boolean indicating if it's terminal.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def env_cleanup(self):\n",
        "        \"\"\"Cleanup done after the environment ends\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def env_message(self, message):\n",
        "        \"\"\"A message asking the environment for information\n",
        "\n",
        "        Args:\n",
        "            message: the message passed to the environment\n",
        "\n",
        "        Returns:\n",
        "            the response (or answer) to the message\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MazeEnvironment(BaseEnvironment):\n",
        "    \"\"\"Implements the environment for an RLGlue environment\n",
        "\n",
        "    Note:\n",
        "        env_init, env_start, env_step, env_cleanup, and env_message are required\n",
        "        methods.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.maze_dim = [6, 9]\n",
        "        self.obstacles = [[1, 2], [2, 2], [3, 2], [4, 5], [0, 7], [1, 7], [2, 7]]\n",
        "\n",
        "        self.start_state = [2, 0]\n",
        "        self.end_state = [0, 8]\n",
        "        self.current_state = [None, None]\n",
        "\n",
        "        reward = None\n",
        "        observation = None\n",
        "        termination = None\n",
        "        self.reward_obs_term = [reward, observation, termination]\n",
        "\n",
        "    def env_init(self, agent_info={}):\n",
        "        \"\"\"Setup for the environment called when the experiment first starts.\n",
        "\n",
        "        Note:\n",
        "            Initialize a tuple with the reward, first state observation, boolean\n",
        "            indicating if it's terminal.\n",
        "        \"\"\"\n",
        "\n",
        "        self.reward_obs_term = [0.0, None, False]\n",
        "\n",
        "    def env_start(self):\n",
        "        \"\"\"The first method called when the experiment starts, called before the\n",
        "        agent starts.\n",
        "\n",
        "        Returns:\n",
        "            The first state observation from the environment.\n",
        "        \"\"\"\n",
        "        self.current_state = self.start_state\n",
        "        self.reward_obs_term[1] = self.get_observation(self.current_state)\n",
        "\n",
        "        return self.reward_obs_term[1]\n",
        "\n",
        "    # check if current state is within the gridworld and return bool\n",
        "    def out_of_bounds(self, row, col):\n",
        "        if row < 0 or row > self.maze_dim[0]-1 or col < 0 or col > self.maze_dim[1]-1:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # check if there is an obstacle at (row, col)\n",
        "    def is_obstacle(self, row, col):\n",
        "        if [row, col] in self.obstacles:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def get_observation(self, state):\n",
        "        return state[0] * self.maze_dim[1] + state[1]\n",
        "\n",
        "    def env_step(self, action):\n",
        "        \"\"\"A step taken by the environment.\n",
        "\n",
        "        Args:\n",
        "            action: The action taken by the agent\n",
        "\n",
        "        Returns:\n",
        "            (float, state, Boolean): a tuple of the reward, state observation,\n",
        "                and boolean indicating if it's terminal.\n",
        "        \"\"\"\n",
        "\n",
        "        reward = 0.0\n",
        "        is_terminal = False\n",
        "\n",
        "        row = self.current_state[0]\n",
        "        col = self.current_state[1]\n",
        "\n",
        "        # update current_state with the action (also check validity of action)\n",
        "        if action == 0: # up\n",
        "            if not (self.out_of_bounds(row-1, col) or self.is_obstacle(row-1, col)):\n",
        "                self.current_state = [row-1, col]\n",
        "\n",
        "        elif action == 1: # right\n",
        "            if not (self.out_of_bounds(row, col+1) or self.is_obstacle(row, col+1)):\n",
        "                self.current_state = [row, col+1]\n",
        "\n",
        "        elif action == 2: # down\n",
        "            if not (self.out_of_bounds(row+1, col) or self.is_obstacle(row+1, col)):\n",
        "                self.current_state = [row+1, col]\n",
        "\n",
        "        elif action == 3: # left\n",
        "            if not (self.out_of_bounds(row, col-1) or self.is_obstacle(row, col-1)):\n",
        "                self.current_state = [row, col-1]\n",
        "\n",
        "        if self.current_state == self.end_state: # terminate if goal is reached\n",
        "            reward = 1.0\n",
        "            is_terminal = True\n",
        "\n",
        "        self.reward_obs_term = [reward, self.get_observation(self.current_state), is_terminal]\n",
        "\n",
        "        return self.reward_obs_term\n",
        "\n",
        "    def env_cleanup(self):\n",
        "        \"\"\"Cleanup done after the environment ends\"\"\"\n",
        "        current_state = None\n",
        "\n",
        "    def env_message(self, message):\n",
        "        \"\"\"A message asking the environment for information\n",
        "\n",
        "        Args:\n",
        "            message (string): the message passed to the environment\n",
        "\n",
        "        Returns:\n",
        "            string: the response (or answer) to the message\n",
        "        \"\"\"\n",
        "        if message == \"what is the current reward?\":\n",
        "            return \"{}\".format(self.reward_obs_term[0])\n",
        "\n",
        "        # else\n",
        "        return \"I don't know how to respond to your message\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ShortcutMazeEnvironment(BaseEnvironment):\n",
        "    \"\"\"Implements the environment for an RLGlue environment\n",
        "\n",
        "    Note:\n",
        "        env_init, env_start, env_step, env_cleanup, and env_message are required\n",
        "        methods.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.maze_dim = [6,9]\n",
        "        self.obstacles = [[3,1],[3,2],[3,3],[3,4],[3,5],[3,6],[3,7],[3,8]]\n",
        "\n",
        "        self.start_state = [5,3]\n",
        "        self.end_state = [0,8]\n",
        "        self.current_state = [None, None]\n",
        "\n",
        "        # a shortcut opens up after n timesteps\n",
        "        self.change_at_n = 0\n",
        "        self.timesteps = 0\n",
        "\n",
        "        reward = None\n",
        "        observation = None\n",
        "        termination = None\n",
        "        self.reward_obs_term = [reward, observation, termination]\n",
        "\n",
        "    def env_init(self, env_info={}):\n",
        "        \"\"\"Setup for the environment called when the experiment first starts.\n",
        "\n",
        "        Note:\n",
        "            Initialize a tuple with the reward, first state observation, boolean\n",
        "            indicating if it's terminal.\n",
        "        \"\"\"\n",
        "        self.change_at_n = env_info.get('change_at_n', 100000)\n",
        "        self.timesteps = 0\n",
        "        self.reward_obs_term = [0.0, None, False]\n",
        "\n",
        "    def env_start(self):\n",
        "        \"\"\"The first method called when the experiment starts, called before the\n",
        "        agent starts.\n",
        "\n",
        "        Returns:\n",
        "            The first state observation from the environment.\n",
        "        \"\"\"\n",
        "        self.current_state = self.start_state\n",
        "        self.reward_obs_term[1] = self.get_observation(self.current_state)\n",
        "\n",
        "        return self.reward_obs_term[1]\n",
        "\n",
        "    # check if current state is within the gridworld and return bool\n",
        "    def out_of_bounds(self, row, col):\n",
        "        if row < 0 or row > self.maze_dim[0]-1 or col < 0 or col > self.maze_dim[1]-1:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # check if there is an obstacle at (row, col)\n",
        "    def is_obstacle(self, row, col):\n",
        "        if [row, col] in self.obstacles:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def get_observation(self, state):\n",
        "        return state[0] * self.maze_dim[1] + state[1]\n",
        "\n",
        "    def env_step(self, action):\n",
        "        \"\"\"A step taken by the environment.\n",
        "\n",
        "        Args:\n",
        "            action: The action taken by the agent\n",
        "\n",
        "        Returns:\n",
        "            (float, state, Boolean): a tuple of the reward, state observation,\n",
        "                and boolean indicating if it's terminal.\n",
        "        \"\"\"\n",
        "        self.timesteps += 1\n",
        "        if self.timesteps == self.change_at_n:\n",
        "            self.obstacles = self.obstacles[:-1]\n",
        "\n",
        "        reward = 0.0\n",
        "        is_terminal = False\n",
        "\n",
        "        row = self.current_state[0]\n",
        "        col = self.current_state[1]\n",
        "\n",
        "        # update current_state with the action (also check validity of action)\n",
        "        if action == 0: # up\n",
        "            if not (self.out_of_bounds(row-1, col) or self.is_obstacle(row-1, col)):\n",
        "                self.current_state = [row-1, col]\n",
        "\n",
        "        elif action == 1: # right\n",
        "            if not (self.out_of_bounds(row, col+1) or self.is_obstacle(row, col+1)):\n",
        "                self.current_state = [row, col+1]\n",
        "\n",
        "        elif action == 2: # down\n",
        "            if not (self.out_of_bounds(row+1, col) or self.is_obstacle(row+1, col)):\n",
        "                self.current_state = [row+1, col]\n",
        "\n",
        "        elif action == 3: # left\n",
        "            if not (self.out_of_bounds(row, col-1) or self.is_obstacle(row, col-1)):\n",
        "                self.current_state = [row, col-1]\n",
        "\n",
        "        if self.current_state == self.end_state: # terminate if goal is reached\n",
        "            reward = 1.0\n",
        "            is_terminal = True\n",
        "\n",
        "        self.reward_obs_term = [reward, self.get_observation(self.current_state), is_terminal]\n",
        "\n",
        "        return self.reward_obs_term\n",
        "\n",
        "    def env_cleanup(self):\n",
        "        \"\"\"Cleanup done after the environment ends\"\"\"\n",
        "        current_state = None\n",
        "\n",
        "    def env_message(self, message):\n",
        "        \"\"\"A message asking the environment for information\n",
        "\n",
        "        Args:\n",
        "            message (string): the message passed to the environment\n",
        "\n",
        "        Returns:\n",
        "            string: the response (or answer) to the message\n",
        "        \"\"\"\n",
        "        if message == \"what is the current reward?\":\n",
        "            return \"{}\".format(self.reward_obs_term[0])\n",
        "\n",
        "        # else\n",
        "        return \"I don't know how to respond to your message\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Nw1Jb2YGOnT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ee4fd0b140763673eeaa4eb9568f651c",
          "grade": false,
          "grade_id": "cell-028a2dd8d19ea3a7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pm5j6Q7DOTZ9"
      },
      "outputs": [],
      "source": [
        "plt.rcParams.update({'font.size': 15})\n",
        "plt.rcParams.update({'figure.figsize': [8,5]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8af78c99916d2bef7b8950c06c91ca1b",
          "grade": false,
          "grade_id": "cell-05b0c5c488d26a90",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "RTtD9tb_OTZ9"
      },
      "source": [
        "## Section 1: Dyna-Q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a70fc156a2c433210a5340707627ab14",
          "grade": false,
          "grade_id": "cell-87547eb7b48d2d80",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "IJ8-2_DeOTZ9"
      },
      "source": [
        "Let's start with a quick recap of the tabular Dyna-Q algorithm.\n",
        "\n",
        "<div style=\"width:80%\"><img src=\"./images/DynaQ.png\" alt=\"DynaQ_pseudocode\"></div>\n",
        "\n",
        "Dyna-Q involves four basic steps:\n",
        "1. Action selection: given an observation, select an action to be performed (here, using the $\\epsilon$-greedy method).\n",
        "2. Direct RL: using the observed next state and reward, update the action values (here, using one-step tabular Q-learning).\n",
        "3. Model learning: using the observed next state and reward, update the model (here, updating a table as the environment is assumed to be deterministic).\n",
        "4. Planning: update the action values by generating $n$ simulated experiences using certain starting states and actions (here, using the random-sample one-step tabular Q-planning method). This is also known as the 'Indirect RL' step. The process of choosing the state and action to simulate an experience with is known as 'search control'.\n",
        "\n",
        "Steps 1 and 2 are parts of the [tabular Q-learning algorithm](http://www.incompleteideas.net/book/RLbook2018.pdf#page=153) and are denoted by line numbers (a)â€“(d) in the pseudocode above. Step 3 is performed in line (e), and Step 4 in the block of lines (f).\n",
        "\n",
        "We highly recommend revising the Dyna videos in the course and the material in the RL textbook (in particular, [Section 8.2](http://www.incompleteideas.net/book/RLbook2018.pdf#page=183))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "65b87624638d81a162640d0c59868798",
          "grade": false,
          "grade_id": "cell-feffd3d6e8b4ac8b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WKZjsAYBOTZ-"
      },
      "source": [
        "Alright, let's begin coding.\n",
        "\n",
        "As you already know by now, you will develop an agent which interacts with the given environment via RL-Glue. More specifically, you will implement the usual methods `agent_start`, `agent_step`, and `agent_end` in your `DynaQAgent` class, along with a couple of helper methods specific to Dyna-Q, namely `update_model` and `planning_step`. We will provide detailed comments in each method describing what your code should do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "30cdeb28f5cf7ee8bfe4844ab7b9624b",
          "grade": false,
          "grade_id": "cell-d0135622e9f741c2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "SGFfmBfYOTZ-"
      },
      "source": [
        "Let's break this down in pieces and do it one-by-one.\n",
        "\n",
        "First of all, check out the `agent_init` method below. As in earlier assignments, some of the attributes are initialized with the data passed inside `agent_info`. In particular, pay attention to the attributes which are new to `DynaQAgent`, since you shall be using them later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fcc0e80f7f9aee52e7128caa88d2c7ba",
          "grade": false,
          "grade_id": "cell-5d0e8c43378d5e30",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "TBxD2pzyOTZ-"
      },
      "outputs": [],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "class DynaQAgent(BaseAgent):\n",
        "\n",
        "    def agent_init(self, agent_info):\n",
        "        \"\"\"Setup for the agent called when the experiment first starts.\n",
        "\n",
        "        Args:\n",
        "            agent_init_info (dict), the parameters used to initialize the agent. The dictionary contains:\n",
        "            {\n",
        "                num_states (int): The number of states,\n",
        "                num_actions (int): The number of actions,\n",
        "                epsilon (float): The parameter for epsilon-greedy exploration,\n",
        "                step_size (float): The step-size,\n",
        "                discount (float): The discount factor,\n",
        "                planning_steps (int): The number of planning steps per environmental interaction\n",
        "\n",
        "                random_seed (int): the seed for the RNG used in epsilon-greedy\n",
        "                planning_random_seed (int): the seed for the RNG used in the planner\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        # First, we get the relevant information from agent_info\n",
        "        # NOTE: we use np.random.RandomState(seed) to set the two different RNGs\n",
        "        # for the planner and the rest of the code\n",
        "        try:\n",
        "            self.num_states = agent_info[\"num_states\"]\n",
        "            self.num_actions = agent_info[\"num_actions\"]\n",
        "        except:\n",
        "            print(\"You need to pass both 'num_states' and 'num_actions' \\\n",
        "                   in agent_info to initialize the action-value table\")\n",
        "        self.gamma = agent_info.get(\"discount\", 0.95)\n",
        "        self.step_size = agent_info.get(\"step_size\", 0.1)\n",
        "        self.epsilon = agent_info.get(\"epsilon\", 0.1)\n",
        "        self.planning_steps = agent_info.get(\"planning_steps\", 10)\n",
        "\n",
        "        self.rand_generator = np.random.RandomState(agent_info.get('random_seed', 42))\n",
        "        self.planning_rand_generator = np.random.RandomState(agent_info.get('planning_random_seed', 42))\n",
        "\n",
        "        # Next, we initialize the attributes required by the agent, e.g., q_values, model, etc.\n",
        "        # A simple way to implement the model is to have a dictionary of dictionaries,\n",
        "        #        mapping each state to a dictionary which maps actions to (reward, next state) tuples.\n",
        "        self.q_values = np.zeros((self.num_states, self.num_actions))\n",
        "        self.actions = list(range(self.num_actions))\n",
        "        self.past_action = -1\n",
        "        self.past_state = -1\n",
        "        self.model = {} # model is a dictionary of dictionaries, which maps states to actions to\n",
        "                        # (reward, next_state) tuples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0aabcf332aa74c3e7db51eb0b47ab744",
          "grade": false,
          "grade_id": "cell-ee23a83113d8ed05",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3r3sGXPoOTZ-"
      },
      "source": [
        "Now let's create the `update_model` method, which performs the 'Model Update' step in the pseudocode. It takes a `(s, a, s', r)` tuple and stores the next state and reward corresponding to a state-action pair.\n",
        "\n",
        "Remember, because the environment is deterministic, an easy way to implement the model is to have a dictionary of encountered states, each mapping to a dictionary of actions taken in those states, which in turn maps to a tuple of next state and reward. In this way, the model can be easily accessed by `model[s][a]`, which would return the `(s', r)` tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d6dd59f9c730360c26df3035b85ea17a",
          "grade": false,
          "grade_id": "cell-59c91c0887f0eaea",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "hgK-jt4sOTZ-"
      },
      "outputs": [],
      "source": [
        "%%add_to DynaQAgent\n",
        "\n",
        "# -----------\n",
        "# Graded Cell\n",
        "# -----------\n",
        "\n",
        "def update_model(self, past_state, past_action, state, reward):\n",
        "    \"\"\"updates the model\n",
        "\n",
        "    Args:\n",
        "        past_state       (int): s\n",
        "        past_action      (int): a\n",
        "        state            (int): s'\n",
        "        reward           (int): r\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "    # Update the model with the (s,a,s',r) tuple (1~4 lines)\n",
        "\n",
        "    # ----------------\n",
        "    # your code here\n",
        "    if past_state not in self.model:\n",
        "        self.model[past_state] = {}\n",
        "    self.model[past_state][past_action] = (state, reward)\n",
        "    pass\n",
        "    # ----------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "802b3f2ab731bdccc0adcfc6d4950229",
          "grade": false,
          "grade_id": "cell-f625328c7bd73d13",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "OIKULQvuOTZ_"
      },
      "source": [
        "### Test `update_model()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ab016ddc9bcf9816b2a62407532dede7",
          "grade": true,
          "grade_id": "cell-d4fa9f9e0a14ccfa",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XXOW7gseOTZ_"
      },
      "outputs": [],
      "source": [
        "# -----------\n",
        "# Tested Cell\n",
        "# -----------\n",
        "# The contents of the cell will be tested by the autograder.\n",
        "# If they do not pass here, they will not pass there.\n",
        "\n",
        "actions = []\n",
        "agent_info = {\"num_actions\": 4,\n",
        "              \"num_states\": 3,\n",
        "              \"epsilon\": 0.1,\n",
        "              \"step_size\": 0.1,\n",
        "              \"discount\": 1.0,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 0}\n",
        "\n",
        "agent = DynaQAgent()\n",
        "agent.agent_init(agent_info)\n",
        "\n",
        "# (past_state, past_action, state, reward)\n",
        "agent.update_model(0,2,0,1)\n",
        "agent.update_model(2,0,1,1)\n",
        "agent.update_model(0,3,1,2)\n",
        "\n",
        "expected_model = {\n",
        "    # action 2 in state 0 leads back to state 0 with a reward of 1\n",
        "    # or taking action 3 leads to state 1 with reward of 2\n",
        "    0: {\n",
        "        2: (0, 1),\n",
        "        3: (1, 2),\n",
        "    },\n",
        "    # taking action 0 in state 2 leads to state 1 with a reward of 1\n",
        "    2: {\n",
        "        0: (1, 1),\n",
        "    },\n",
        "}\n",
        "\n",
        "assert agent.model == expected_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4ad7e7911407af12a3ad8dea6a0e83fa",
          "grade": false,
          "grade_id": "cell-a398d6775a6d809a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "mxVtC0UhOTZ_"
      },
      "source": [
        "Next, you will implement the planning step, the crux of the Dyna-Q algorithm. You shall be calling this `planning_step` method at every timestep of every trajectory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2c48cb05d902ca761858cc4c81846350",
          "grade": false,
          "grade_id": "cell-1a90876a079f6ea2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "0-MrVpkbOTZ_"
      },
      "outputs": [],
      "source": [
        "%%add_to DynaQAgent\n",
        "\n",
        "# -----------\n",
        "# Graded Cell\n",
        "# -----------\n",
        "\n",
        "def planning_step(self):\n",
        "    \"\"\"performs planning, i.e. indirect RL.\n",
        "\n",
        "    Args:\n",
        "        None\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    # The indirect RL step:\n",
        "    # - Choose a state and action from the set of experiences that are stored in the model. (~2 lines)\n",
        "    # - Query the model with this state-action pair for the predicted next state and reward.(~1 line)\n",
        "    # - Update the action values with this simulated experience.                            (2~4 lines)\n",
        "    # - Repeat for the required number of planning steps.\n",
        "    #\n",
        "    # Note that the update equation is different for terminal and non-terminal transitions.\n",
        "    # To differentiate between a terminal and a non-terminal next state, assume that the model stores\n",
        "    # the terminal state as a dummy state like -1\n",
        "    #\n",
        "    # Important: remember you have a random number generator 'planning_rand_generator' as\n",
        "    #     a part of the class which you need to use as self.planning_rand_generator.choice()\n",
        "    #     For the sake of reproducibility and grading, *do not* use anything else like\n",
        "    #     np.random.choice() for performing search control.\n",
        "\n",
        "    # ----------------\n",
        "    # your code here\n",
        "    keys = list(self.model.keys())\n",
        "    for _ in range(self.planning_steps):\n",
        "        s = self.planning_rand_generator.choice(keys)\n",
        "\n",
        "        state = self.model[s]\n",
        "\n",
        "        actions = list(state)\n",
        "        a = self.planning_rand_generator.choice(actions)\n",
        "        (new_state, reward) = self.model[s][a]\n",
        "        error =  0.0\n",
        "        if new_state == -1:\n",
        "            #terminal stage\n",
        "            error = self.step_size * (reward + 0  - self.q_values[s][a])\n",
        "        else:\n",
        "            error = self.step_size * (reward + self.gamma * np.max(self.q_values[new_state])  - self.q_values[s][a])\n",
        "        self.q_values[s][a] = self.q_values[s][a] + error\n",
        "        #print(self.q_values)\n",
        "    # ----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "edbac5139f888befba4b2696d25fed12",
          "grade": false,
          "grade_id": "cell-35c7dcb9a38dd319",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "IVyGtXYSOTZ_"
      },
      "source": [
        "### Test `planning_step()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f8e02d9152bf919f6755239ef071f37c",
          "grade": true,
          "grade_id": "cell-8ae4b7a941ad7767",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "g3A2IBIWOTaA"
      },
      "outputs": [],
      "source": [
        "# -----------\n",
        "# Tested Cell\n",
        "# -----------\n",
        "# The contents of the cell will be tested by the autograder.\n",
        "# If they do not pass here, they will not pass there.\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "actions = []\n",
        "agent_info = {\"num_actions\": 4,\n",
        "              \"num_states\": 3,\n",
        "              \"epsilon\": 0.1,\n",
        "              \"step_size\": 0.1,\n",
        "              \"discount\": 1.0,\n",
        "              \"planning_steps\": 4,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 5}\n",
        "\n",
        "agent = DynaQAgent()\n",
        "agent.agent_init(agent_info)\n",
        "\n",
        "agent.update_model(0,2,1,1)\n",
        "agent.update_model(2,0,1,1)\n",
        "agent.update_model(0,3,0,1)\n",
        "agent.update_model(0,1,-1,1)\n",
        "\n",
        "expected_model = {\n",
        "    0: {\n",
        "        2: (1, 1),\n",
        "        3: (0, 1),\n",
        "        1: (-1, 1),\n",
        "    },\n",
        "    2: {\n",
        "        0: (1, 1),\n",
        "    },\n",
        "}\n",
        "\n",
        "assert agent.model == expected_model\n",
        "\n",
        "agent.planning_step()\n",
        "\n",
        "expected_values = np.array([\n",
        "    [0, 0.1, 0, 0.2],\n",
        "    [0, 0, 0, 0],\n",
        "    [0.1, 0, 0, 0],\n",
        "])\n",
        "assert np.all(np.isclose(agent.q_values, expected_values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a3534e47ea52ac6c4180d714a0e01e37",
          "grade": false,
          "grade_id": "cell-02566293dd5feb36",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ft9vyZNNOTaA"
      },
      "source": [
        "Now before you move on to implement the rest of the agent methods, here are the helper functions that you've used in the previous assessments for choosing an action using an $\\epsilon$-greedy policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7d55430e58877032febb23ecb4ba8efd",
          "grade": false,
          "grade_id": "cell-cc975f6b2f1a6661",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "LErBa7FxOTaA"
      },
      "outputs": [],
      "source": [
        "%%add_to DynaQAgent\n",
        "\n",
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "def argmax(self, q_values):\n",
        "    \"\"\"argmax with random tie-breaking\n",
        "    Args:\n",
        "        q_values (Numpy array): the array of action values\n",
        "    Returns:\n",
        "        action (int): an action with the highest value\n",
        "    \"\"\"\n",
        "    top = float(\"-inf\")\n",
        "    ties = []\n",
        "\n",
        "    for i in range(len(q_values)):\n",
        "        if q_values[i] > top:\n",
        "            top = q_values[i]\n",
        "            ties = []\n",
        "\n",
        "        if q_values[i] == top:\n",
        "            ties.append(i)\n",
        "\n",
        "    return self.rand_generator.choice(ties)\n",
        "\n",
        "def choose_action_egreedy(self, state):\n",
        "    \"\"\"returns an action using an epsilon-greedy policy w.r.t. the current action-value function.\n",
        "\n",
        "    Important: assume you have a random number generator 'rand_generator' as a part of the class\n",
        "                which you can use as self.rand_generator.choice() or self.rand_generator.rand()\n",
        "\n",
        "    Args:\n",
        "        state (List): coordinates of the agent (two elements)\n",
        "    Returns:\n",
        "        The action taken w.r.t. the aforementioned epsilon-greedy policy\n",
        "    \"\"\"\n",
        "\n",
        "    if self.rand_generator.rand() < self.epsilon:\n",
        "        action = self.rand_generator.choice(self.actions)\n",
        "    else:\n",
        "        values = self.q_values[state]\n",
        "        action = self.argmax(values)\n",
        "\n",
        "    return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e4704ddcf5cfaad469470f8397c9397d",
          "grade": false,
          "grade_id": "cell-50858ea1e5f5db91",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gA1OOBOVOTaA"
      },
      "source": [
        "Next, you will implement the rest of the agent-related methods, namely `agent_start`, `agent_step`, and `agent_end`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ae45bcd826ba619bf18f2513c80b4079",
          "grade": false,
          "grade_id": "cell-34d9e8a161d6e5b4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "OD1VQkTkOTaA"
      },
      "outputs": [],
      "source": [
        "%%add_to DynaQAgent\n",
        "\n",
        "# -----------\n",
        "# Graded Cell\n",
        "# -----------\n",
        "\n",
        "def agent_start(self, state):\n",
        "    \"\"\"The first method called when the experiment starts,\n",
        "    called after the environment starts.\n",
        "    Args:\n",
        "        state (Numpy array): the state from the\n",
        "            environment's env_start function.\n",
        "    Returns:\n",
        "        (int) the first action the agent takes.\n",
        "    \"\"\"\n",
        "\n",
        "    # given the state, select the action using self.choose_action_egreedy()),\n",
        "    # and save current state and action (~2 lines)\n",
        "    ### self.past_state = ?\n",
        "    ### self.past_action = ?\n",
        "\n",
        "    # ----------------\n",
        "    # your code here\n",
        "    self.past_state = state\n",
        "    self.past_action = self.choose_action_egreedy(state)\n",
        "    # ----------------\n",
        "\n",
        "    return self.past_action\n",
        "\n",
        "def agent_step(self, reward, state):\n",
        "    \"\"\"A step taken by the agent.\n",
        "\n",
        "    Args:\n",
        "        reward (float): the reward received for taking the last action taken\n",
        "        state (Numpy array): the state from the\n",
        "            environment's step based on where the agent ended up after the\n",
        "            last step\n",
        "    Returns:\n",
        "        (int) The action the agent takes given this state.\n",
        "    \"\"\"\n",
        "\n",
        "    # - Direct-RL step (~1-3 lines)\n",
        "    # - Model Update step (~1 line)\n",
        "    # - `planning_step` (~1 line)\n",
        "    # - Action Selection step (~1 line)\n",
        "    # Save the current state and action before returning the action to be performed. (~2 lines)\n",
        "\n",
        "    # ----------------\n",
        "    # your code here\n",
        "    #print(f\"step reward {reward}, state {state}\")\n",
        "    #calculate previous state value\n",
        "    q_s_a = self.q_values[self.past_state][self.past_action]\n",
        "    error = self.step_size* (reward + self.gamma * np.max(self.q_values[state])  - q_s_a)\n",
        "\n",
        "    #update previous state/action value\n",
        "    self.q_values[self.past_state][self.past_action] = error\n",
        "    #update model (past_state, past_action, state, reward)\n",
        "    self.update_model(self.past_state, self.past_action, state, reward)\n",
        "    #planning\n",
        "    self.planning_step()\n",
        "    #select next action\n",
        "    self.past_action = self.choose_action_egreedy(state)\n",
        "    self.past_state = state\n",
        "    #print(\"q_values\",self.q_values)\n",
        "    #print(\"model\",self.model)\n",
        "    # ----------------\n",
        "\n",
        "    return self.past_action\n",
        "\n",
        "def agent_end(self, reward):\n",
        "    \"\"\"Called when the agent terminates.\n",
        "\n",
        "    Args:\n",
        "        reward (float): the reward the agent received for entering the\n",
        "            terminal state.\n",
        "    \"\"\"\n",
        "\n",
        "    # - Direct RL update with this final transition (1~2 lines)\n",
        "    # - Model Update step with this final transition (~1 line)\n",
        "    # - One final `planning_step` (~1 line)\n",
        "    #\n",
        "    # Note: the final transition needs to be handled carefully. Since there is no next state,\n",
        "    #       you will have to pass a dummy state (like -1), which you will be using in the planning_step() to\n",
        "    #       differentiate between updates with usual terminal and non-terminal transitions.\n",
        "\n",
        "    # ----------------\n",
        "    # your code here\n",
        "    #print(f\"end reward {reward}\")\n",
        "    #calculate previous state value\n",
        "    q_s_a = self.q_values[self.past_state][self.past_action]\n",
        "    #print(\"q_s_a\",q_s_a)\n",
        "    error = self.step_size* (reward + 0  - q_s_a)\n",
        "\n",
        "    #update previous state/action value\n",
        "    self.q_values[self.past_state][self.past_action] = error\n",
        "\n",
        "    #update model\n",
        "    self.update_model(self.past_state, self.past_action, -1, reward)\n",
        "    #planning\n",
        "    self.planning_step()\n",
        "    # ----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "684b56621417ff95a833db909acbc2b9",
          "grade": false,
          "grade_id": "cell-13ed73c6c6df5630",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HnfVEaWcOTaB"
      },
      "source": [
        "### Test `agent_start()`, `agent_step()`, and `agent_end()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8ce595f374dc31897a6698cae3652bef",
          "grade": true,
          "grade_id": "cell-02b41cfa4e281a4f",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JkGyTTFhOTaB"
      },
      "outputs": [],
      "source": [
        "# -----------\n",
        "# Tested Cell\n",
        "# -----------\n",
        "# The contents of the cell will be tested by the autograder.\n",
        "# If they do not pass here, they will not pass there.\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "agent_info = {\"num_actions\": 4,\n",
        "              \"num_states\": 3,\n",
        "              \"epsilon\": 0.1,\n",
        "              \"step_size\": 0.1,\n",
        "              \"discount\": 1.0,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_steps\": 2,\n",
        "              \"planning_random_seed\": 0}\n",
        "\n",
        "agent = DynaQAgent()\n",
        "agent.agent_init(agent_info)\n",
        "\n",
        "# ----------------\n",
        "# test agent start\n",
        "# ----------------\n",
        "\n",
        "action = agent.agent_start(0)\n",
        "\n",
        "assert action == 1\n",
        "assert agent.model == {}\n",
        "assert np.all(agent.q_values == 0)\n",
        "\n",
        "# ---------------\n",
        "# test agent step\n",
        "# ---------------\n",
        "\n",
        "action = agent.agent_step(1, 2)\n",
        "assert action == 3\n",
        "\n",
        "action = agent.agent_step(0, 1)\n",
        "assert action == 1\n",
        "\n",
        "expected_model = {\n",
        "    0: {\n",
        "        1: (2, 1),\n",
        "    },\n",
        "    2: {\n",
        "        3: (1, 0),\n",
        "    },\n",
        "}\n",
        "assert agent.model == expected_model\n",
        "\n",
        "expected_values = np.array([\n",
        "    [0, 0.3439, 0, 0],\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0, 0, 0],\n",
        "])\n",
        "assert np.allclose(agent.q_values, expected_values)\n",
        "\n",
        "# --------------\n",
        "# test agent end\n",
        "# --------------\n",
        "\n",
        "agent.agent_end(1)\n",
        "\n",
        "expected_model = {\n",
        "    0: {\n",
        "        1: (2, 1),\n",
        "    },\n",
        "    2: {\n",
        "        3: (1, 0),\n",
        "    },\n",
        "    1: {\n",
        "        1: (-1, 1),\n",
        "    },\n",
        "}\n",
        "assert agent.model == expected_model\n",
        "\n",
        "expected_values = np.array([\n",
        "    [0, 0.41051, 0, 0],\n",
        "    [0, 0.1, 0, 0],\n",
        "    [0, 0, 0, 0.01],\n",
        "])\n",
        "assert np.allclose(agent.q_values, expected_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ebc65986e4b7d2a58cbaa4fc22508593",
          "grade": false,
          "grade_id": "cell-58a0061ef19de5af",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8rbZsEY6OTaB"
      },
      "source": [
        "### Experiment: Dyna-Q agent in the maze environment\n",
        "\n",
        "Alright. Now we have all the components of the `DynaQAgent` ready. Let's try it out on the maze environment!\n",
        "\n",
        "The next cell runs an experiment on this maze environment to test your implementation. The initial action values are $0$, the step-size parameter is $0.125$. and the exploration parameter is $\\epsilon=0.1$. After the experiment, the sum of rewards in each episode should match the correct result.\n",
        "\n",
        "We will try planning steps of $0,5,50$ and compare their performance in terms of the average number of steps taken to reach the goal state in the aforementioned maze environment. For scientific rigor, we will run each experiment $30$ times. In each experiment, we set the initial random-number-generator (RNG) seeds for a fair comparison across algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6f1ce118374c859b81ca1a743bc1bd9b",
          "grade": false,
          "grade_id": "cell-744f017993777ec8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "33bZHtOiOTaC"
      },
      "outputs": [],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "def run_experiment(env, agent, env_parameters, agent_parameters, exp_parameters):\n",
        "\n",
        "    # Experiment settings\n",
        "    num_runs = exp_parameters['num_runs']\n",
        "    num_episodes = exp_parameters['num_episodes']\n",
        "    planning_steps_all = agent_parameters['planning_steps']\n",
        "\n",
        "    env_info = env_parameters\n",
        "    agent_info = {\"num_states\" : agent_parameters[\"num_states\"],  # We pass the agent the information it needs.\n",
        "                  \"num_actions\" : agent_parameters[\"num_actions\"],\n",
        "                  \"epsilon\": agent_parameters[\"epsilon\"],\n",
        "                  \"discount\": env_parameters[\"discount\"],\n",
        "                  \"step_size\" : agent_parameters[\"step_size\"]}\n",
        "\n",
        "    all_averages = np.zeros((len(planning_steps_all), num_runs, num_episodes)) # for collecting metrics\n",
        "    log_data = {'planning_steps_all' : planning_steps_all}                     # that shall be plotted later\n",
        "\n",
        "    for idx, planning_steps in enumerate(planning_steps_all):\n",
        "\n",
        "        print('Planning steps : ', planning_steps)\n",
        "        os.system('sleep 0.5')                    # to prevent tqdm printing out-of-order before the above print()\n",
        "        agent_info[\"planning_steps\"] = planning_steps\n",
        "\n",
        "        for i in tqdm(range(num_runs)):\n",
        "\n",
        "            agent_info['random_seed'] = i\n",
        "            agent_info['planning_random_seed'] = i\n",
        "\n",
        "            rl_glue = RLGlue(env, agent)          # Creates a new RLGlue experiment with the env and agent we chose above\n",
        "            rl_glue.rl_init(agent_info, env_info) # We pass RLGlue what it needs to initialize the agent and environment\n",
        "\n",
        "            for j in range(num_episodes):\n",
        "\n",
        "                rl_glue.rl_start()                # We start an episode. Here we aren't using rl_glue.rl_episode()\n",
        "                                                  # like the other assessments because we'll be requiring some\n",
        "                is_terminal = False               # data from within the episodes in some of the experiments here\n",
        "                num_steps = 0\n",
        "                while not is_terminal:\n",
        "                    reward, _, action, is_terminal = rl_glue.rl_step()  # The environment and agent take a step\n",
        "                    num_steps += 1                                      # and return the reward and action taken.\n",
        "\n",
        "                all_averages[idx][i][j] = num_steps\n",
        "\n",
        "    log_data['all_averages'] = all_averages\n",
        "\n",
        "    return log_data\n",
        "\n",
        "\n",
        "def plot_steps_per_episode(data):\n",
        "    all_averages = data['all_averages']\n",
        "    planning_steps_all = data['planning_steps_all']\n",
        "\n",
        "    for i, planning_steps in enumerate(planning_steps_all):\n",
        "        plt.plot(np.mean(all_averages[i], axis=0), label='Planning steps = '+str(planning_steps))\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.xlabel('Episodes')\n",
        "    plt.ylabel('Steps\\nper\\nepisode', rotation=0, labelpad=40)\n",
        "    plt.axhline(y=16, linestyle='--', color='grey', alpha=0.4)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f4b740a35fbe720e8ecc73ade69dd3cd",
          "grade": false,
          "grade_id": "cell-b7c90063cc0888e0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Z2Jsq9AzOTaC",
        "outputId": "8b8dc947-978d-4934-a4d1-35a4680ee43f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Planning steps :  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:14<00:00,  2.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Planning steps :  5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Planning steps :  50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [01:12<00:00,  2.41s/it]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"num_runs\" : 30,                     # The number of times we run the experiment\n",
        "    \"num_episodes\" : 40,                 # The number of episodes per experiment\n",
        "}\n",
        "\n",
        "# Environment parameters\n",
        "environment_parameters = {\n",
        "    \"discount\": 0.95,\n",
        "}\n",
        "\n",
        "# Agent parameters\n",
        "agent_parameters = {\n",
        "    \"num_states\" : 54,\n",
        "    \"num_actions\" : 4,\n",
        "    \"epsilon\": 0.1,\n",
        "    \"step_size\" : 0.125,\n",
        "    \"planning_steps\" : [0, 5, 50]       # The list of planning_steps we want to try\n",
        "}\n",
        "\n",
        "current_env = ShortcutMazeEnvironment   # The environment\n",
        "current_agent = DynaQAgent              # The agent\n",
        "\n",
        "dataq = run_experiment(current_env, current_agent, environment_parameters, agent_parameters, experiment_parameters)\n",
        "plot_steps_per_episode(dataq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "81c7635453f9c560e71d536f7e7be762",
          "grade": false,
          "grade_id": "cell-a44baca574f0e70c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JxTv4Al1OTaD"
      },
      "source": [
        "What do you notice?\n",
        "\n",
        "As the number of planning steps increases, the number of episodes taken to reach the goal decreases rapidly. Remember that the RNG seed was set the same for all the three values of planning steps, resulting in the same number of steps taken to reach the goal in the first episode. Thereafter, the performance improves. The slowest improvement is when there are $n=0$ planning steps, i.e., for the non-planning Q-learning agent, even though the step size parameter was optimized for it. Note that the grey dotted line shows the minimum number of steps required to reach the goal state under the optimal greedy policy.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "92986c0d6a6e9acfaf3cbab5ebafbf49",
          "grade": false,
          "grade_id": "cell-753d3ebd700359e6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "GRrSPJJeOTaD"
      },
      "source": [
        "### Experiment(s): Dyna-Q agent in the _changing_ maze environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "dd09e132177a8cc9b4a061de27754ad4",
          "grade": false,
          "grade_id": "cell-aa3974b49e4eda2f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0eNilFzLOTaD"
      },
      "source": [
        "Great! Now let us see how Dyna-Q performs on the version of the maze in which a shorter path opens up after 3000 steps. The rest of the transition and reward dynamics remain the same.\n",
        "\n",
        "<img src=\"./images/shortcut_env_after.png\" alt=\"environment\" width=\"800\"/>\n",
        "\n",
        "Before you proceed, take a moment to think about what you expect to see. Will Dyna-Q find the new, shorter path to the goal? If so, why? If not, why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e89fe28e52a88aeed2388ac7afad4ab3",
          "grade": false,
          "grade_id": "cell-422bb22d0465830f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4hAEzIWzOTaD"
      },
      "outputs": [],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "def run_experiment_with_state_visitations(env, agent, env_parameters, agent_parameters, exp_parameters, result_file_name):\n",
        "\n",
        "    # Experiment settings\n",
        "    num_runs = exp_parameters['num_runs']\n",
        "    num_max_steps = exp_parameters['num_max_steps']\n",
        "    planning_steps_all = agent_parameters['planning_steps']\n",
        "\n",
        "    env_info = {\"change_at_n\" : env_parameters[\"change_at_n\"]}\n",
        "    agent_info = {\"num_states\" : agent_parameters[\"num_states\"],\n",
        "                  \"num_actions\" : agent_parameters[\"num_actions\"],\n",
        "                  \"epsilon\": agent_parameters[\"epsilon\"],\n",
        "                  \"discount\": env_parameters[\"discount\"],\n",
        "                  \"step_size\" : agent_parameters[\"step_size\"]}\n",
        "\n",
        "    state_visits_before_change = np.zeros((len(planning_steps_all), num_runs, 54))  # For saving the number of\n",
        "    state_visits_after_change = np.zeros((len(planning_steps_all), num_runs, 54))   #     state-visitations\n",
        "    cum_reward_all = np.zeros((len(planning_steps_all), num_runs, num_max_steps))   # For saving the cumulative reward\n",
        "    log_data = {'planning_steps_all' : planning_steps_all}\n",
        "\n",
        "    for idx, planning_steps in enumerate(planning_steps_all):\n",
        "\n",
        "        print('Planning steps : ', planning_steps)\n",
        "        os.system('sleep 1')          # to prevent tqdm printing out-of-order before the above print()\n",
        "        agent_info[\"planning_steps\"] = planning_steps  # We pass the agent the information it needs.\n",
        "\n",
        "        for run in tqdm(range(num_runs)):\n",
        "\n",
        "            agent_info['random_seed'] = run\n",
        "            agent_info['planning_random_seed'] = run\n",
        "\n",
        "            rl_glue = RLGlue(env, agent)  # Creates a new RLGlue experiment with the env and agent we chose above\n",
        "            rl_glue.rl_init(agent_info, env_info) # We pass RLGlue what it needs to initialize the agent and environment\n",
        "\n",
        "            num_steps = 0\n",
        "            cum_reward = 0\n",
        "\n",
        "            while num_steps < num_max_steps-1 :\n",
        "\n",
        "                state, _ = rl_glue.rl_start()  # We start the experiment. We'll be collecting the\n",
        "                is_terminal = False            # state-visitation counts to visiualize the learned policy\n",
        "                if num_steps < env_parameters[\"change_at_n\"]:\n",
        "                    state_visits_before_change[idx][run][state] += 1\n",
        "                else:\n",
        "                    state_visits_after_change[idx][run][state] += 1\n",
        "\n",
        "                while not is_terminal and num_steps < num_max_steps-1 :\n",
        "                    reward, state, action, is_terminal = rl_glue.rl_step()\n",
        "                    num_steps += 1\n",
        "                    cum_reward += reward\n",
        "                    cum_reward_all[idx][run][num_steps] = cum_reward\n",
        "                    if num_steps < env_parameters[\"change_at_n\"]:\n",
        "                        state_visits_before_change[idx][run][state] += 1\n",
        "                    else:\n",
        "                        state_visits_after_change[idx][run][state] += 1\n",
        "\n",
        "    log_data['state_visits_before'] = state_visits_before_change\n",
        "    log_data['state_visits_after'] = state_visits_after_change\n",
        "    log_data['cum_reward_all'] = cum_reward_all\n",
        "\n",
        "    return log_data\n",
        "\n",
        "def plot_cumulative_reward(data_all, item_key, y_key, y_axis_label, legend_prefix, title):\n",
        "    data_y_all = data_all[y_key]\n",
        "    items = data_all[item_key]\n",
        "\n",
        "    for i, item in enumerate(items):\n",
        "        plt.plot(np.mean(data_y_all[i], axis=0), label=legend_prefix+str(item))\n",
        "\n",
        "    plt.axvline(x=3000, linestyle='--', color='grey', alpha=0.4)\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel(y_axis_label, rotation=0, labelpad=60)\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ed82204e60d5cda36d818ca9bf653710",
          "grade": false,
          "grade_id": "cell-142b14ac90c9bff7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "cxSLapwhOTaE"
      },
      "source": [
        "Did you notice that the environment changes after a fixed number of _steps_ and not episodes?\n",
        "\n",
        "This is because the environment is separate from the agent, and the environment changes irrespective of the length of each episode (i.e., the number of environmental interactions per episode) that the agent perceives. And hence we are now plotting the data per step or interaction of the agent and the environment, in order to comfortably see the differences in the behaviours of the agents before and after the environment changes.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4f802c06e5b1eb84585c6876ac3f2dd3",
          "grade": false,
          "grade_id": "cell-0b246e0fe5abb018",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "KQBGcod2OTaE"
      },
      "source": [
        "Okay, now we will first plot the cumulative reward obtained by the agent per interaction with the environment, averaged over 10 runs of the experiment on this changing world."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "20b0026f54442a7ba37d7096128e03ed",
          "grade": false,
          "grade_id": "cell-9f7872900ce6b40f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9A4iCBaDOTaE",
        "outputId": "f0a2db0e-0581-41c2-91ec-274da1359706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Planning steps :  5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Planning steps :  10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:15<00:00,  1.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Planning steps :  50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:10<00:00,  7.06s/it]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"num_runs\" : 10,                     # The number of times we run the experiment\n",
        "    \"num_max_steps\" : 6000,              # The number of steps per experiment\n",
        "}\n",
        "\n",
        "# Environment parameters\n",
        "environment_parameters = {\n",
        "    \"discount\": 0.95,\n",
        "    \"change_at_n\": 3000\n",
        "}\n",
        "\n",
        "# Agent parameters\n",
        "agent_parameters = {\n",
        "    \"num_states\" : 54,\n",
        "    \"num_actions\" : 4,\n",
        "    \"epsilon\": 0.1,\n",
        "    \"step_size\" : 0.125,\n",
        "    \"planning_steps\" : [5, 10, 50]      # The list of planning_steps we want to try\n",
        "}\n",
        "\n",
        "current_env = ShortcutMazeEnvironment   # The environment\n",
        "current_agent = DynaQAgent              # The agent\n",
        "\n",
        "dataq = run_experiment_with_state_visitations(current_env, current_agent, environment_parameters, agent_parameters, experiment_parameters, \"Dyna-Q_shortcut_steps\")\n",
        "plot_cumulative_reward(dataq, 'planning_steps_all', 'cum_reward_all', 'Cumulative\\nreward', 'Planning steps = ', 'Dyna-Q : Varying planning_steps')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ce1264bf93c93926107e736687bfe3ab",
          "grade": false,
          "grade_id": "cell-ae67d282ebad19ad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zp1dyBnhOTaE"
      },
      "source": [
        "We observe that the slope of the curves is almost constant. If the agent had discovered the shortcut and begun using it, we would expect to see an increase in the slope of the curves towards the later stages of training. This is because the agent can get to the goal state faster and get the positive reward. Note that the timestep at which the shortcut opens up is marked by the grey dotted line.\n",
        "\n",
        "Note that this trend is constant across the increasing number of planning steps.\n",
        "\n",
        "Now let's check the heatmap of the state visitations of the agent with `planning_steps=10` during training, before and after the shortcut opens up after 3000 timesteps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bfe46c5772be65c97fa8ba81d947f985",
          "grade": false,
          "grade_id": "cell-c21d98bc4f7296d6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "RC6gqTO1OTaE"
      },
      "outputs": [],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "def plot_state_visitations(data, plot_titles, idx):\n",
        "    data_keys = [\"state_visits_before\", \"state_visits_after\"]\n",
        "    positions = [211,212]\n",
        "    titles = plot_titles\n",
        "    wall_ends = [None,-1]\n",
        "\n",
        "    for i in range(2):\n",
        "\n",
        "        state_visits = data[data_keys[i]][idx]\n",
        "        average_state_visits = np.mean(state_visits, axis=0)\n",
        "        grid_state_visits = np.rot90(average_state_visits.reshape((6,9)).T)\n",
        "        grid_state_visits[2,1:wall_ends[i]] = np.nan # walls\n",
        "        #print(average_state_visits.reshape((6,9)))\n",
        "        plt.subplot(positions[i])\n",
        "        plt.pcolormesh(grid_state_visits, edgecolors='gray', linewidth=1, cmap='viridis')\n",
        "        plt.text(3+0.5, 0+0.5, 'S', horizontalalignment='center', verticalalignment='center')\n",
        "        plt.text(8+0.5, 5+0.5, 'G', horizontalalignment='center', verticalalignment='center')\n",
        "        plt.title(titles[i])\n",
        "        plt.axis('off')\n",
        "        cm = plt.get_cmap()\n",
        "        cm.set_bad('gray')\n",
        "\n",
        "    plt.subplots_adjust(bottom=0.0, right=0.7, top=1.0)\n",
        "    cax = plt.axes([1., 0.0, 0.075, 1.])\n",
        "    cbar = plt.colorbar(cax=cax)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ee68fcbd81419dd6d30abaaa38f5a48d",
          "grade": false,
          "grade_id": "cell-aa17be852a4fa1e1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "029i2aY5OTaE",
        "outputId": "98ad4947-9771-4316-f7c2-25a80a1083c7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApAAAAGKCAYAAAC7EHEwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeZgcZbn+8e+dAAlZSMIqshgWNSICIiJglH0VRBEBWWIUV44Loqhw5AAeFdCjHAU3fgch7CCyGAFZjciqgOw7GDAiSyAhZCNh8vz+eN9OOjU9M92ZSnqmcn+uq69kqt+qerq6uvrpdytFBGZmZmZmzRrQ7gDMzMzMrH9xAmlmZmZmLXECaWZmZmYtcQJpZmZmZi1xAmlmZmZmLXECaWZmZmYtcQJpbSFpvKSQtMMSrDtZ0qTyo+pxv2dL6vPzXkkanY/tCUtp+1tIulHStKW5n6VB0g455vHtjqW/8DEzs0Z6TCDrLh61R0f+4nhQ0gRJe0jSsgh2aZA0SNJXJN0mabqkuZKelPRLSRss5X1vLunCvL+5kqZKul/SryW9u67cSEknLEmy1WCfJ0j6SG+309dIOrKML7ic2B5ZQkiVJGkF4HfAW4HjgMOAy9oaVEFOoE+QtEW7YzEzq6oVWih7IXA1IGA48HbgI8A44AZJH4+I6eWHuPRIWgu4Bng3cD1wAjAT2BwYD4yTdFBETFwK+94buAJ4CTgHeBIYCYwB9gOeAP6ei48Ejs//n9TLXR8PTMj7bqdzgYuAeUuw7tuBYk3gkcBk4OxeRZXe99HA/zZ47rPAF3q5/f5uw/z4ekSc3u5gujCadJ5PBu5tayRmZhXVSgJ5T0ScV79A0lHAD4GjSAnmniXGtlTlWtPfkpLHz0fEGYXnTwX+DFwkaauIeKTkEE4C5gDvjYgphX2vCKxa8v76lIjoADqWcN3XSw6n2f3OB+a3Y999yJvyv6+UudH8eRwaETPL3K6ZmS0lEdHtA9iBVNvzjW7K/CWXGZv/Pir/vUuDsoNIXz431i2bTKpZGwNcBbwGvApcCrypsP6bgR+TahamAXOBh4FvAQN7ej1129knx3hxN2X2ymV+2+Q2NwLGNFl2LnBXC8e/+JhcV+YI4DrgX6QavX8D5wGj68qM7mI7UdjfLnlb03OM9wNfaCLOkbn8ZV08f1Le3xb57/H57x3qygwm1QI/BszOMTwA/KiwrcnApLq/G76u2usHdgMuBp4mJe3T82vcvsF2G21nh/z82cXjlZdvBlwOvFx3Pn6zeD7W1gdGAL8EXszlbwXeVygrUq3q/aTPw4x8XM4EVuzhvai91ycAn8jbmAs8m5et0GCdtXNMz+Zz6DngDGDNujKTejjOQ/P7/BTwOvA8qXb9LV2c0+OB/8jH63XghLoyBwK35Nc+G7gT2L+J83B8FzFOarDvTwEP5X0/A3yzi21uld/fqbnsY8B/NjqO3cTV1OeKJq+FwBfz6/hwg20MAKYA9zYZ28eAP+XYZufX9zNgpSU5ZjT5eas7pyaTrusXkq7ps4Brgbd1cW7/jvR5eBW4EtiAwjVhCY77dqTWqOdzuX+RWty2afY99sOP5e3Rc4HmEsjaRfuk/Pdq+UN4YYOyB+WyB9ctm0xqsn2e9CX2hfzvAuC6wvp7AP8AfkL68jkyX2wC+HXTLzw14zZMcuvKCPhnvggOamKbk2mQYHRR9qG83e16KLdWfo1B6mt2aH58pK7M08AFpCT6s8BP80X4OWC1XGZoXi+Am+u2c2jddj6Xj/ltwNGkxPTyvM6PmnhNl5C+WFYtLB9ASkzua3DO7FC37My8bEI+B/6D1JR8d4PjPKnu70NJXQEeqX9dpBot8rGpdVH4DKl585/AG8AH6rbzkbyNlwrbWSs/f3bx/SUlF7NIX1DfB75M+sIK4PxC2bPz8juAicCXciyvkpLP4XVlj8tlf5/fh88DJ5OSrWE9vA+j87p3F+K6Pi8/q1B+fdIX5kt5H58FTiF9ST8BjMjlds3bCuDX9ceZ1JpxS37utznmU0nXgeeBdRtcU+7N78N/kc69PfPz38vPX0M6979CSnAC+I8eXvuGXcS4a2Hfd5CuI9/J78MdFK5LufxepHP6IeCY/D6cTao9b/aHZdOfK5q8FgKj8rG9tMH+ds3b/loTsdWO1UOkc/Fz+b1/Ehi5hMesqc9bLjuJdN49SfrR+0VSq9brpM/iwLqyq+XtzCMluF/M+5qctzFpSY47qUvMLNIPn2OATwPHkhL4zzfzHvvhx/L46LlAcwnklrnM7+qWXZAvcMVk4npSDeTgumWT8/oHFMr+PC8fU7dsZUANYjiXdFFfu6kXnr5coxhfg3ITc7lNm9jmZJpPIPfPF7cg/Sr+Vb5wjW5QdnQud0IX2xraYNnOeZ1vFpYHcHaD8mvn9+uCBs/9NB/bjXp4TR/K2z+ii1iOqls2ns4J5CvA1U0e50k9Levh+KxFqlG6urB8EnW1u4Xnzi6+v6TawzeAzeqWiZRMB7BzcX3gF4VtfDwv/3zdsnuAh5s5l7o5XzqALQtx1b5At6lbfiWpNnTdwna2yq/thLplO+T1xxfKfjYv/2EX58S5DbbxCnU1nPm52rXkBw1e1xWkpHZ4D6+/YYyF554jJ0h5+RBSEnJ73bLBpETuZgq1jcDXiudvF7G09LmitWvhb/O2RxXKnkvqarFWD7Ftnbd5E3XX47pzRa0esyX8vDW6Th2dl+9et+yHedkhhbK15ZPqljV93Ek/UALYekk+b374sbw+yprGZ0b+d5W6ZWeQmqsPqS2QNJqUTJwfEXML23guIi4pLLsp/7txbUFEzImIyNtbSdKqklYn1UIOIH3pNaMW66s9lKs9P7ynDUbE6IhoakR6RFwKfJDUNLUeqWbjTOAfkq6UtEYz28nbmgUgaYCkEfl43Jdjf1+Tm9mf9H6dKWn1+gcpiR5Aeu+6cy3wAmlgVb1xpAv2+T2s/yrwTkmbNhlzU2rHB0DSMEmr5XjupPnj04mkNUlNX7+PiPvr9hfAD/KfH22w6qmFv2vn+Vvrlr0KrCNp7JLGB1wfEfcU4vphfVySRgB7k2o65xbe98mkmqHdmtjXR0k/iE6qXxgRV5FqGveVVLzenBMRLxaWHUKuhW5wHv6e9Dnctol4enJW1A36i4jZpBq1+vdgV1LicxYwshDL1blMT8dmST5XTV0LSTX1g0jN/UA6v0nvxR8j4oUeYqtdm48pXo8jK5Rv5pgtyedtAalGsV6jz8Q+pO45FxbK/k+DbbZy3GvX+H0lDW6wLTNroJVBNN2pJWO1RJKImCTpceBw4LS8+FOkX7b/12AbTzdY9nL+d7XagjyNyLdJScnGeXv1RuVyA4FiEjYnImoXi1qsI+h+QEDttfV0MW5ZRNwC3JIHELwV2JHUzPJhUnPO7s1sR9JOpGbA95FqTeqNajKcd+R/b+imzFrdbSAi3pB0AfA1SW+LiMclDSWNKm/mC+1IUu3JA5KeJjVbTgQmRsSCpl5FA5I2IjXV7U7qq7lY2Eu6XVLfK0jNf0UPk74YN2zw3GLnekS8nGfCWq1u8bGkGre/SHqOVFNzFanJstmR640Gfj2c/63F9XbSl+nh+dFIo89m0QakxGdag+ceArYAVifVdNY83qDsO0if6Ue72Ve352GTurre1L8Htc/Eb3oRy5J8rpq6FgJ/JB3PcaQWDEj9GYeSksuevJV0/t/XRNnu4qqPaUk+b881qFBo9Ho3AP5avBZExIuSijOAtHLcLyJ1cziWdO26g/Rj+KKIeKab9c2Wa2UlkJvlfx8rLP9/wI8kvYc0Jc140sCRRhes7kbk1ieJPyH157qYdJF6kdRcsyWp706tlmM9Un+dehNyDAAP5nW2pPuLzLtJTSFTuinTK/mX/uPA45ImkL5wd5O0bhRGaBdJei+pz92TpMT6H6S+lUG6MDZby1w7xuNIv/IbaSaRmEBq3htH6iu1HzCMNJiiWxFxZa6l3gvYntQB/nBSErVLC4nTQrlG5mbSl+r/kgblvEZK7o4Bdmp1m/WbX5KVIo1A73Z7EXF7/iLenfTDYkfgYOA7ksZGRDOjoJtJjmv7PI+uk445LWynFbO72E6QZnTo6jg1Sthb1cwMALXXdDRdTwf0XJPbaOVz1dS1sO4H25GSNo6IJ/N+ppF+ePWkdqyb1eMxW8LPW7PX/lY0fdwjzeqwq6StSZ+3DwLfBU6QdHBEXL6EMZhVWlkJZK3m4qrC8rNJSd7hpH5W61No4loChwE3R8RB9QslbVwo9zypCape/cX+d6SLy2foIoGUtAewLqn/1pLMV9iyiJgr6V5SDdE6pMS1u4v8wcBA0gCEhQlzrvlrtvYRUsd9gKkR0V1C3a2IuE/SfcChko4jHePppObHZtZ/hZTMnJdrZk8mjWjel9Tnq8tVu1i+M2mE56cj4qz6JyR9r4XtNFL74n9ng+fGkJL3ZpLuhiJNafO7/EDSEaS+cIcDP2piE5t0s6wW15Ok17xSb9530gCEPSSNjM7zwW5CqvGf2sR2niANlHs2lnzqrN7UKhdjAZjVi2NTyueqGxNINffjJJ1B6q94RjQ31dVjpGO9GfDXkuJp9fPWisnAxpIG1NdC5q4kxZrOlo97RPyVfBwkrUeq9Pgeqd+wmRX0qg+kpIGS/gcYS+ocfWv98xExldQMdzBp1N5s0uCa3uig8Ks0J0tfK+x7bkTcUHg8XFdkImn6oQMlfbrBaxtNGsU5k5TE9EjSRpLGNFm24R18ct/H95MGL9QugrW58RrNDVn79V7c1rE0fn9ndrGd2gjqEyWt3CCuEZIGNVivkQnAW0jv+06kqZKKTVTF7Q+UtNiXQK6ZrU2m3tO8mF29robHR9JuNO6PNRMY1ei9Kcr9924D9qnvt5nXPSb/uURfPrmvVlGtP2Ozc4TuKmnLQlzfzH9eAan5nNSfbz9J2zSIQ032x72CdL59u7D+nqRa/N832Q3h3PzvD3I3lGI8azaxje4+L624ltTC8W1JnbYlaWVJPfWNLvNz1UlE3EsahHco6cfaAJprvoZF1+IfNIqhmc9AA61+3loxkTQ45hOF5d9oULbp497FZ20KaYBQpefjNeuNVmogt5R0aP5//Z1o3kJqQj24i/XOAA4gddSfEBEzuijXrEuBz0u6mFRzuBZp9PLL3a5VEBEh6eOkfkRnSjqA9EU6i/SL/FO56EGFxLM7N5KORzMX3kuBFyX9gdQv7Q1SreNhpNf03VozZe4j9yRwkKSnSP0xZ0W6Q87lpOT56lwDMY9U87oZjWt87gB2kfQt0tQ6EREXRcQUSV8k9U99RNK5pHne1gDeRXqvNyHVAvTkfNJgjV/Q/BfacODfkn5PShpfJPV5+iLNNcndARwu6b9Jff8W5HVuIdVG/zj/KJhC6o93GKl57V0NtrM3cLqk20hfiDc1GOxR81XShPN/kfTzvK+9SU1hF0TEjU289kYeyX2x7iTVnK9NmpZkHqlrQjPuA27Kcf2bVIu7C6lG/fa6cl8kHaebJZ1DOv4DSOfjvqTuByf0sK+zgU8C38rH+WZSH+UjSOfrsc0EHBF/k3Q8cCJwr6Tfsuj1v4fUvWGlHjbzMKnZ9AhJtflEX4yIm7pfrVMssySNIyXHj0n6DZ3vGPVRurk7VMmfq65MIM2N+y3g8Yi4o5mVIuKvkk7J692dr6nPkz53+5NGabd6d7FWP2+tOIX0PXNWbm5+lFR58X7StW5hzXOLx/07OcH9A6kLkEgDdsawaNCZmRX1NEybzhNZd5BGrT1EunDt0cP6ItWkBYU5wOrKTKbxJLC1fY+vWzaE1Hz3DKlv4hOkWo+di2WbeZBG6n0VuD2/rtrrfAFYp8VtTab5aXw+Tuqc/xApQZqf93kN8LEG5bcmTRkzK8c3ue65j5CmJZpFupBeROou0Om4kjrOX0dqUoxivKSL8eWkBK42ofSfgK9TmOqjh9dXm/7o8S6eH0/dNCikpOAkUhPSy6Tag8n5GL21p/MFWJPU1PsKi6ZHGp2f24z0Q2EaKbGYBHyAxtPyDCWNhn8hn+v1MXYqn5dvTkoyXmHR/HVdTiTexfEI6qZXyuf0zfl9eJ00/91vqZuWp5tjPzpv7wQWTSRe28Z3aTAROWmAy49IfXHnsmgS958Cm3T3mSwcu5NIzePzcuzn0s1E4t28hg+RagBrx/SfpM/GF5s8//Yi1djOpW6Klx7i7+r93ZTUraI2Uf8LpJrn4+hhGrBWP1e0cC2se24t0vUjgP9s9jNat/4nSNeW10jXkEdJ/Rc7TSTezDGjtc/bJBpMm0UXU5eRktvLWDS5fm0i8U5TBDV73PPruzgf+zn5nLuT1L2p05RxfvjhR3rU5vlaqiQ9RPoybap5t90knU6axPpnEfHVdsdjZmaNKU0TNJV0I4nl/V71ZstMWYNouqQ0xcwmpF98/cWXSTViX5E0JyK+3dMKZma2dElaOSKKswJ8K/97/bKOx2x5ttRqIHPiuBFpMMEw0qz/ry2VnZmZWeVJmkTqvnQXafaJnUl9jm8DPhhdT5FlZiVbmgnkJFIH54dJ96/9y1LZkZmZLRckfZ002nw06ba2U0h9Ik90BYXZsrVM+kCamZmZWXWUdS9sMzMzM1tOLPVBNP3JiSee6OpYM7MeHH/88Ut6i0Gztth9x6Hx8iv9o4vs3fe/fm1E7NHuOHriBLLgluv7ziEZu+sbANz8pxXbHMkiH9xxPgB/un1wmyNJdtw23eDmpr92utlE2+y0dRokOvHZnm5Ssuzss37qHvbHx4a1OZJF9nh7umHMtQ/3nZh23yTFdOPdQ9ocSbLze9Ltwq98fpU2R7LIvm/q7b0gzJa9l1/p4K/Xrt/uMJoycO0nGt0dqc/pO9mSmZmZ2VIQwAKauZuqNcsJpJmZmVVc0BFOIMvkQTRmZmZm1hLXQJqZmVmlpSZsj5MtkxNIM7OKm/6PB5j60K3MfmkKC+a/zgqDhzJ07Q1ZY9MPMGztDdodntky4T6Q5XICaWZWYVNuvYKXHvwLq75tK9Z/53asMGgo82ZOY9qTf+eJK09jk08cy6AR/WLQp9kSC4IO3zilVE4gzcwqavo/HuSlB25m/R0OYrUxWy/23Kpv24pXJz/EgBX6zjRhZtZ/OIE0M6uolx74M0PWWK9T8lgzYvQ7l3FEZu3jPpDlcgJpZlZBsaCDWS88w5qb79DuUMzaLoAOJ5ClcgJpZlZBb8ydTXS8wUrDRi62PCKgfj48DUDynQnNrDVOIM3MKqlW27J4cvjifZN47o6JC/9ed+xHWWPTDyzDuMzaw03Y5XICaWZWQSsMHooGrsD8WdMXW77q27Zi+Js3BuCxy05tR2hmy1yAR2GXzAmkmVkFacBAhq71Fmb88zHWfu+eC5evOGQ4Kw4Z3sbIzNrDs0CWy7cyNDOrqDXetT2zX3yWVx6/q92hmFnFuAbSzKyiRm6wKWu864M886cLee1fTzJi9CasMHgYb8ydxWtTHgdgwAqD2hyl2dIXhEdhl8wJpJlZha37/o8w7M0bMvXB23h20sV0zH+dFQYPY+hab2HDvT7LiPXf0e4QzZa+gA7nj6VyAmlmVnEjN9iMkRts1u4wzKxCnECamZlZpQUeRFM2J5BmZmZWcaIDT5hfJieQZmZmVmkBLHAfyFJ5Gh8zMzMza4lrIM3MzKzy3IRdLieQZmZmVmmBE8iyuQnbzMzMzFriGsiCsbu+0e4QOvngjvPbHUInO247t90hLGanree0O4RO9ln/tXaH0Mkeb5/Z7hA62X2TvhfTzu+Z3e4QFrPvm2a0OwSzfm9BVKcGUtLGwNHANsCmwF8iYoduyv8v8FXgxxHxjcJzmwCnAdsC04H/A06MiI7uYnACaWZmZpVWwSbsdwJ7AXcAK3VXMCeInwY6/RKVNAq4AXgY2BfYCPgxqYX6O91t1wlkwWXTVml3CAvtNyq915fO6Dsx7b9KiunK5/pGTPu+OcVz050rtzmSRXZ6X6oNvfHuIW2OZJFajdrtl85rcySLbLt/uubdNrHvzK2x3T7pC+aOi19vcyTJNgem+1Tffnm3FQHL1LYfHdjuEMxaFoiOavXamxgRVwJIuhRYvZuyPwN+ChzW4LkvACsD+0XEDOB6SasAJ0j6YV7WUKWOppmZmVnVRURTN9aRtD/wDuDkLorsCVxbSBQvIiWV23e3bddAmpmZWeVVqQ9kMyStTGqO/nZEzJIavv4xwE31CyLiWUmz83MTu9q+E0gzMzOrtAr2gWzGMcC/gfO6KTOKNHCmaFp+rktOIM3MzMz6jtUl3VX39xkRcUYrG5C0AfANYKeI6KmjeaPn1cXyhZxAmpmZWcWJjug3wz6mRsRWvdzGycA1wKOSRuZlA4BB+e9Xc2I5DRjZYP0RNK6ZXMgJpJmZmVVaAAuWr3HDbwc2B/YrLP9SfqwHTAEeJfV1XEjSesDQ/FyXnECamZlZ5S1nfSA/AwwrLLsI+DPwS+ClvOwa4GhJwyOidveLA4E5uWyXnECamZmZ9SOShpAmEgdYB1glT9kDcHVE3NVgnbnAPyNiUt3iXwFfAS6TdAqwIXAC8JPu5oAEJ5BmZmZWcRH9qg9kM9YEfltYVvt7A2ByMxuJiGmSdgZOJ03ZMx04lZREdssJpJmZmVXeggo1YUfEZGjtBUXE6C6WPwzs1GoMlUrHzczMzGzpcw2kmZmZVVqaSNx1ZmVyAmlmZmYVV7k+kG3nBNLMzMwqbTmcB3Kp89E0MzMzs5a4BtLMzMwqryOqMwq7L3ACaWZmZpUWyINoSuajaWZmZmYtcQ2kmZmZVd4Cj8IulRNIMzMzqzTPA1k+H00zMzMza4lrIM3MzKzSAnkUdsmcQJqZmVnleSLxcjmBNDMzs0qLwLcyLJkTyIL9Rs1odwid7L9K34tp3zf3rZh2et+cdofQyc7vmd3uEDrZdv+V2h1CJ9vt0/ealbY5cFC7Q1jMth8d2O4QzMwW4wTSzMzMKk4soO/9WO3PnEAW3L/rC+0OYaHNrl8LgPNXWKXNkSxyyBup5vF3r/aNmD42IsXz+yl9Ix6AD6+bYrruwWFtjmSR3TadCcCfb+k7NWvbj30dgFuu7Tu1a2N37wDg9tP+1eZIkm2/vA4At5z4YJsjWWTs8Zu2OwSzlgVuwi6bj6aZmZmZtcQ1kGZmZlZ5nki8XE4gzczMrNICscDzQJbKCaSZmZlVnmsgy+WjaWZmZmYtcQ2kmZmZVVoACzwKu1ROIM3MzKziRIfngSyV03EzMzMza4lrIM3MzKzS3IRdPieQZmZmVnluwi6XE0gzMzOrtAi5BrJkPppmZmZm1hLXQJqZmVnldbgGslROIM3MzKzSAljgPpClcjpuZmZmZi1xDaSZmZlVnNyEXTInkGZmZlZpaR5IN2GXyQmkmZmZVV6He+2VykfTzMzMzFriGkgzMzOrtEBuwi6ZE0gzMzOrvAVudC2Vj6aZmZmZtcQ1kGZmZlZpEdDhJuxSOYE0MzOzynMfyHI5gTQzM7NKS4No3GuvTE4gCza7fq12h9DJIW/MaHcInXxsRN+K6cPr9q14AHbbdGa7Q+hk+7GvtzuETsbu3tHuEDrZ9svrtDuExYw9ftN2h2BmthgnkGZmZlZ5HbgJu0xOIAtWO/DP7Q5hoZcv3r7dIZiZmfV7vpVh+dwhwMzMzKwfkbSxpF9Luk9Sh6RJhefXlvSj/PxMSf+UNEHSmxtsaxNJN0qaLek5Sd+VNLCnGFwDaWZmZhVXuUE07wT2Au4AVmrw/HuAjwL/B9wJrAWcANwmadOImAkgaRRwA/AwsC+wEfBjUgXjd7oLwAmkmZmZVd6CavWBnBgRVwJIuhRYvfD8LcCYiHijtkDSPcBjwMeACXnxF4CVgf0iYgZwvaRVgBMk/TAva8gJpJmZmVVa1SYSj4gFPTw/vcGyxyXNBtasW7wncG0hUbwIOAXYHpjY1T4qVZ9rZmZmZp1J2gwYQmqurhkDPFpfLiKeBWbn57rkGkgzMzOrvIr1gWyJpAHAT4EngOvqnhoFdKqtBKbl57rkBNLMzMwqLd2Jpt80Ya8u6a66v8+IiDN6uc2TgG2B7SNifuG5aFBeXSxfyAmkmZmZWd8xNSK2Kmtjko4AjgY+ERF3Fp6eBoxssNoIGtdMLuQE0szMzCqvYqOwmyLpY8BpwDcj4uIGRR6l0NdR0nrAUAp9I4ucQJqZmVmlLY93opG0A3A+cHpE/E8Xxa4BjpY0PCJey8sOBOYA3d6azwmkmZmZWT8iaQhpInGAdYBVJO2f/74aeAtwBakW8WJJ29St/lJEPJX//yvgK8Blkk4BNiRNOP6T7uaABCeQZmZmthyo2CjsNYHfFpbV/t4AeB+pH+PmwK2FchOA8QARMU3SzsDppDkfpwOnkpLIbjmBNDMzs2qLfjUKu0cRMRm67dR5dn40s62HgZ1ajcEJpJmZmVVasHwOolmaKlWfa2ZmZmZLn2sgzczMrPKq1ITdFziBNDMzs0pbHqfxWdrchG1mZmZmLXENpJmZmVWeayDL5QTSzMzMKi2o1jQ+fYETSDMzM6s8T+NTLveBNDMzM7OWuAbSzMzMqi3cB7JsTiDNzMys0jyNT/mcQBa8fPH27Q7BzMzMrE9zAmlmZmaV5xrIcjmBLNjw4GvaHcJCT1+wJwDzPnpfmyNZZKXLNwfgXx96us2RJOtctSEAv9uyo82RLPKxewYCcO6Q4W2OZJHDZr8GwLmDV2lzJIscNncGABdG34npE0oxnTOsb7x342am9+2q973e5kgW+dCdg9odglnLPI1P+ZxAmpmZWeWFE8hSeRofMzMzM2uJayDNzMys8jyReLmcQJqZmVmlheeBLJ2bsM3MzMysJa6BNDMzs8rzIJpyOYE0MzOzivM0PmVzAmlmZmaV5xrIcrkPpJmZmZm1xDWQZmZmVmmBR2GXzQmkmZmZVVukqXysPG7CNjMzM7OWuAbSzMzMKs93oimXE0gzMzOrtMCjsMvmBNLMzMwqzvNAls19IM3MzMysJa6BNDMzs8rzKOxyOYE0MzOzynMfyHK5CdvMzMzMWuIaSDMzM6u0CNdAls0JpJmZmVWeR2GXy6HfoacAACAASURBVAmkmZmZVZ4H0ZTLfSDNzMzMrCWugTQzM7PKcx/IcjmBLHj6gj3bHUInK12+ebtD6GSdqzZsdwiL+dg9A9sdQieHzX6t3SF0ctjcGe0OoZNPqO/FNG5m33rvPnTnoHaHYNavBXICWTI3YZuZmZlZS1wDWXD2Riu1O4SFxj81D4BLtug7PX8PuDf9gpu6z+NtjiRZfeLbADju8+e3OZJF/vvXhwBwztDhbY5kkXGzUo3aeSut0uZIFjl0Xqp5PH+FvhPTIW/kmAb2jZgO6UjxzPrIg22OZJGhV2za7hDMlkjf+SatBieQZmZmVm2eB7J0bsI2MzMzs5a4BtLMzMyqz23YpXICaWZmZpXnJuxyuQnbzMzMKi/dD7vvP5ohaWNJv5Z0n6QOSZMalJGkYyX9U9IcSTdL2qJBuU0k3ShptqTnJH1XUo9z4zmBtOXe2RfP4L27PcuIjZ9ktTFP8Z5dn+Xrx7/U7rDMzMy68k5gL+Dx/Gjk28BxwCnAPsBM4AZJb6oVkDQKuIHUwL8v8F3g68CJPQXgBNKWayf/7BU+9/UX2G2HIVx65tqc/bO1+PDuQ5l43ax2h2ZmZiUJUhN2f3g0aWJErBcRHwceKj4paTApgTwpIk6PiBuAj+dD8aW6ol8AVgb2i4jrI+JXpOTxKEndzmfmPpC2XPv5WdP53GEj+P6xqy9cts9uw/ivr6/axqjMzKxUAVSoD2RELOihyHbAKsAldevMkjQR2BP4Tl68J3BtRNTfEuwiUq3l9sDErnbgGkhbrk1/dQFvWqNzVw+pOhcaMzNb7owBOoAnCssfyc/Vl3u0vkBEPAvMLpTrxDWQtlzb8l2DOP03r7Leuiuy9y5DWW3VvndPbTMz671mB6hUxChgZkR0FJZPA4ZIWiki5uVy0xusPy0/1yXXQNpy7bST1mTYUPHpr77AWps+zbu2f4bjf/gyM14rfubMzKxfi37ygNUl3VX3+FwvXnGRGjzXVbluU27XQNpybbNNBvHQzW/huj/P5rpJs/nTLXP43qmvcPGVr3HXdeszbKh/Y5mZ9X8tDVBpt6kRsVUvtzENGC5pYKEWciQwOyLm15Ub2WD9ETSumVzI34623Bs0aAD77DaM036wJg/e/BbO+PGaPPH0fH5zwavtDs3MzGxJPAoMBDYuLC/2eXyUQl9HSesBQwvlOnECaVZw+MEjWHXUAB59cn7Phc3MrH9od9N0803YZbgNmEGaugcASUNI80FeU1fuGmB3ScPrlh0IzAH+3N0O3IRty7UXp77Bmqsv/jF4aeobvDpjAWs1GJ1tZmb9UNCfmrB7lJPBvfKf6wCrSNo//311RMyWdDJwnKRppNrEo0gVh6fVbepXwFeAyySdAmwInAD8pDC1TydOIG25tvmOz/Lh3Yey6w5DWHO1FXhmynx+8qtpDFl5AOMO6HYOVTMzs3ZZE/htYVnt7w2AycDJpITxGGA14C5g14h4obZCREyTtDNwOmnOx+nAqaQksltOIG25dtxRq3LlH2dx5Hde4pXpaU7Ibd87mAt/tTYbrL9iu8MzM7OyVGgan4iYzKIR1V2VCeD7+dFduYeBnVqNwQmkLdeO+NRIjvhUowFoZmZWLdVpwu4LnECamZlZ9VWoBrIv8ChsMzMzM2uJayDNzMys+lwDWSonkGZmZlZtAVRoGp++wE3YZmZmZtYS10CamZlZ5YWbsEvlBLJg/FPz2h1CJwfc2/eq3Vef+LZ2h7CY//71Ie0OoZNxs15rdwidHDqv2xsLtMUhb/TBmDr6VkxDr9i03SGY9X9OIEvlBLLO8ccf3/cyNTMzM+s994EslftAmpmZmVlLXANpZmZmlSc3YZfKCaSZmZlVW+A+kCVzE7aZmZmZtcQ1kGZmZlZx8iCakjmBNDMzs+pzE3apnECamZlZ9TmBLJX7QJqZmZlZS1wDaWZmZtXnGshSOYE0MzOzags8iKZkbsI2MzMzs5a4BtLMzMwqz3eiKZcTSDMzM6s+J5ClchO29UmSxksKSTsswbqTJU0qP6oe93u2VL3fuJIGSDpB0tOS3ujrr1HSJEmT2x1Hf+JjZmat6nUCKWmH/EVfe3RImibpQUkTJO0hqd/2XJU0SNJXJN0mabqkuZKelPRLSRss5X1vLunCvL+5kqZKul/SryW9u67cyPwFv0MJ+zxB0kd6u52+RtKRksaXsJ3xko4sIaT+5JPA8cCfgMOBw8o855bEcvo+mJn1GWU2YV8IXA0IGA68HfgIMA64QdLHI2J6iftb6iStBVwDvBu4HjgBmAlsDowHxkk6KCImLoV97w1cAbwEnAM8CYwExgD7AU8Af8/FR5K+4AEm9XLXxwMT8r7b6VzgImDeEqz7djo3VhwJTAbO7lVU6X0fDfxvg+c+C3yhl9vvi3YFXgU+ExEBIGk05Z1zS2I8Xb8PZmad9O22k/6nzATynog4r36BpKOAHwJHkRLMPUvc31KVa01/S0oePx8RZxSePxX4M3CRpK0i4pGSQzgJmAO8NyKmFPa9IrBqyfvrUyKiA+hYwnVfLzmcZvc7H5jfjn0vZW8CpteSx2VB0vCIeG1Z7c/MlgOexqdUS7UPZER0RMTXgVuAPSSNhZRY5ubuXYrr5CbjVyTdWLdscu6jM0bSVZJek/SqpEslvamw/psl/VjSvbkpfa6khyV9S9LAFsLfG/gAcEkxecyv7Wng88AQ4LvNbFDSRpLGNLn/twKPFZPHvO/5EfFC3uYOwD/yU8fXdSWYXLffIyRdJ+lfkuZJ+rek83ItUq3M6Lq+bZ+s75ZQeA275G3VmvPvl9RjrVtu8pwr6bIunj8p72+L/HenPpCSBudm08ckzc4xPCDpR4VtLdYHMr+GtwDbF7pbjM7P7ybpYqU+fnPydq+TtH1xu8D2wFsK29khP9+wD6SkzSRdLunluvPxm8Xzsba+pBFKXSRezOVvlfS+QlnlZvn78+dhRj4uZ+YfGN1q8pzYIb+eHQuveTI9nHN5/QMl3ZLjmy3pTkn7N4gl8mvfOZefCXRZq9/T+1BX7s1KXUCmSZol6VpJb2uwvUGSjpX0UD7e0yVNVF03kZ7k9+wUpe4mr0t6Ke97w0K52nm9k6RvSHoql39c0ifryg3M7809Xezv83k7PXY3kfQmST/L5/fr+by6XtKuDcr2eMwkDZf0vfx+Ts3bfFLSyZKGFMrWujiNl/SpfIxfl/SMpG92Ee8X87k8Nx+XL6mLPtEtHPemrh1m1rxlNQr7TGAs8CFSMjkB+AGpP9UNhbIfBUbldeqtQ2oquxw4mtSM/HlgFWC3unKbkZp4LweeAlYk1XyeDGyY12lG7Yvu/3VT5hpgCrC3pEFN1HzdSEpkmvkZ9BTwTknbRcRt3ZR7BPgacCrpNdcStJl1Zb4B3AH8DHgF2BT4DLCTpHdFxMukpvLDSE3HfwE6Jc2SPgf8Km/r+8AsUvPmLyVtFBFHdxVkREyX9HtgX0mrRsQrddsdABwC3B8R93bzWn8OfJrUpH8qMJCUaO/UzTrk13UqMDXHXfNS/nc8qUb3HNL7uQ7p+NwoaceI+EsudySpZnh10jGv6bL2WdJWpJrq+Tn+54F9gFNI5/AhDVa7Nsf2XWA1Ug3+1ZJG19XKfSc/P5H0nnQAGwAfBgbRc01oM+fEI6Rj95+F1/xPUs18l+ecpO/l9f4IHAcsIH22fyvpSxHx80I8WwEfI33eJvQQezPvw1Dg5vwajyUdm68CV0raNNdw12rz/whsRzr3TwdGkLoj3CrpgxFxV3fBSBoB3AasD/wGeAhYGzgCuFOpheKZwmo/AFYGfg28DnwROFvSkxFxa0R0SDofODrH+2Bh/XGk8/mqHmIbDdwKrEU6v+/Kx2YbYBdS15yWjhmLPh+/Ay4A3iAl9N8knRe7NwjlCzmGM4HpwKHAKZKmRMQFdfF+i3StvifHMIR0vX+puMEWj/uSXjusKgKPwi7Zskog78//vg0gIl5Wqonar5hMkJLKaSz6UqrZGDgwIi6pLZC0ADhC0piIeDQv/jOwYaG57X8lnQt8RtIJEfHvJmLeNP/bsAYgv46QdC+ptvKtQPEi3xvHA5eQvsQeIF0o/wrcFBGT62J4QdIVpIvi/cVuBNm7ImJW/YKczN1AOt4/zM+fl4/T0w26I6xNSjYuioiD6576haSfAkdJ+lVEPNXNa5oAfBw4CPhF3fIdgfXouT/bR4FrIuKTPZRbTESclxOaF7o4Pp9tcHx+RfpCOoaUUBMRVygN3Fi5i+008lNSQrdtRNyft306cDFwsKTfRMSNhXXuiYgj6mJ5mHQuHExKOCAdi0ci4sOFdb/dZFzNnBMvkM6Jz1B4zZKeoYtzTtKWpOTxpIg4tu6pn+Vz9SRJ5xSaqN8J7BoRxR+UnTT5PqwO/CgiflgX10ukLjW7kJJ0gC8BOwB7RMS1dWV/Qfo8/09+vjvfJf043SYi7qvbxtnAA8CJpB8p9QaRuqfMy2UvBZ7O8dyay0wgJU/jSMlZbbsbkRLe03K3ie78Anhz8fXl7RRboJo9Zk8D6xX2/XNJ/w18R9LWEfHXwrbXBzap9YOX9BvgGeDLpCQUSauS+pk/ALw/Iubm5f8HPNbgtbVy3Jfo2mEV4wSyVMtqGp8Z+d9V6padQbqILqyByb+WdwbOr1086jxXnzxmN+V/N64tiIg5dR39V5K0qqTVSRe/AaSajmbUYn21h3K154f3tMGIGB3RXCeMiLgU+CBwKSm5+jzp1/s/JF0paY1mtpO3NQsWTscyIh+P+3Ls7+t25UX2J71fZ0pavf5BqgUbQHrvunMt8ALpC7HeOFIN2vk9rP8qqVZ20x7KtaQ+kZI0TNJqOZ47af74dCJpTdIX/e9ryWPeX5BqoCB9sRWdWvi7dp6/tW7Zq8A6yt1CWlXSOdGVQ0iX6gkNzpXfkz4r2xbWua+Z5LEFC0g/eOo1Oo6HAo8CdxfiXIlUOzdW0spd7USSSK/3ZuBfhW3MItXm7dZg1V/UkkeAiPgX8Hh9bBHxEHA3cEgh2at9frqtqc0J2R7AH4vJY97+gsKipo5ZRMyrJY+SVpA0Kr/e2vvX6Pw5q34QZUTMJh2b+vdiV2Aw8Mv6639EPE/h2rAEx32pXDvMlmfLqgaylozVEkkiYpKkx0m1HaflxZ8iNe/+X4NtPN1g2cv539VqCyStQKqFGUdKLIsJ26hcbiBQTMLmREQtIazFOoLUxNeV2mt7oZsySyQibgFuyRfLt5Jq6o4gNVOeR+Omok4k7QT8F+nCPrjw9Kgmw3lH/re7L/m1uttARLwh6QLga5LeFhGPSxpK6nLwx1q/zm4cSWpmfEDS06RpZSYCExt8GTYt1+h8n3Q8RxbDXtLtkpoAIdVkFj1M+sLesMFzi53rucYe6s5zUvPeFcBfJD1H6t5xFXBpfWLSlZLOia68g/S5e7SbMsVz5fFe7rPouQY/QjtdL0ixrkyDJtI6q5Oa7RtZI29vt2620ejc7Op69pbCsnNItdi7ANflZYcCD0XE3d3EDIuuf3/voVxNs8cMSUeQmqXfSeeKiEbnT1evt367tc9Lo9rG4rJWj/tSuXZY/+JR2OVaVgnkZvnf4kXg/wE/kvQe0kVuPHBXfXNEne5G5NYniT8hNYtcTEoKXiT1B9uS1O+sdrFbj0UDAWomsKjJ48G8zpZ0nzS9G5hL6ju3VOQaq8eBxyVNICUku0lat9Egm3qS3kv64nmSlFj/gzS6O0jT5DRbC107xuOArroANPqSKJpA6rc2jtSPbz9gGOmLslsRcWWupd6L1OdqF9IPkL9I2qWZxKlI0jBSLcZQUhP6A8BrpC+fY+hdH6klGvJX19esy+1FxO058d2d9MNiR1IT93ckjS10C1l8I+WdE13uIm9rT7r+3BaT6tm93GdRs9cLkd7zo7op311yWdvWDaTrS7N6fI+zC0jN6OOA6yR9gPSj41tN7KO2rWa/Nps6Zkqza/yYdA79DHiONN3WOqRpshqdP83MqNDK56Wl4740rh3WDzmBLNWySiAPz/8WO3yfTUryDgeuJPWTOamX+zoMuDkiDqpfKGnjQrnnSU0m9Z6r+//vSBftz9BFAilpD2Bd4NxldQGKiLm53+WGpAv2FLr/WBxM6jC+Z0QsTJhzzV8rNU1P5H+n9qapMSLuk3QfcKik40jHeDqpabOZ9V8h1b6el2tmTyb1D9uXNO1Sl6t2sXxnUh+xT0fEWfVP5H6TzW6nkVpC/c4Gz40hfdE2k3Q3FBEzSefp72BhrdDPSZ+n7kaXlnFOdHccniA1nT4b5U9v1cz+W/EEqTbrpiWsiXqJdP6uUnITPAARMVXS1cBH84+dcaQfN830wX2CdJyaHk3epMNIc6ruWX/M8vWwN2rn4ttZ1HRO3bJ6LR/3Xlw7rCqcQJZqqfaBVJqK4n9II7Cvjohb65+PiKmkZriDSZ3HZ5M7VPdCB4VfsvmLsX60JhExNyJuKDwerisykTR44kBJn27w2kaTBjTMJF2IeqQWpvFRF3fwyX0f308a+VhL6mqjXxvNDVn75V/c1rE0fv9ndrGdS0ijRU9s1Ccs96Mb1GC9RiaQmuoOJtXwXdyg6ay4/YGSFmtezjWztea5nubF7Op1NTw+knajcV+umcCoRu9NUUS8SBr8tE9936u87jH5z8t72k4jua9XUW3AV0/HotVzopHuzrlz878/UIOps3Lf0N5q+n3owTmkeS4b1kAq3UygSzmBOh/YWg2mKMrb6O3rnUAajXwoaRDa9RHxXPerLEyYrgH2VOMp05b02HWQvorrayVrXYd643ryiHRJC7tVKE3VtthsBa0c9xKuHWbWQJk1kFtKOjT/v/5ONG8hNXUc3MV6ZwAHkEYyT4iIGV2Ua9alwOclXUyqOVyLNH3Dy92uVRARIenjpCk+zpR0AOlOO7NITfKfykUPKiSe3WllGp9LgRcl/YHUX+4NUq3jYaTX9N1aM2XuI/ckcJCkp0j9MWdFukPO5aTk+WpJZ5CamnbNr2Fqg/3eAeyiNJ3Gs/lQXBQRUyR9kdQ/9RGl0drPkGpv3kV6rzch1Uz05HzSyM5fkBKWnqZtgXRO/VtppPDfSV0TNiBNfzKNbuYNrHtdhyuNFH2EVIszkTSt1PPAj/OPginAFqTj/EB+bcXt7A2cLuk20pfpTTlZbOSrpJkB/iKpNo3P3qSm5wsajMBu1iOS7iAN9HmONH3J50jv70U9rNvqOdFJd+dcRPxN0vGkUbD3SvptXYzvITUjrtTSq+2s1fehKz8lvfYf5X6hN5H6P69Pqp2eS+oe0J3/JP2ou0TSJTm2eaTP+l6kgTDjW4yr3lWk69cppD7XzXxear5E+hFzTe7+cjepz+f7SJ/VZprCiy4ltRRdozSbxiqk63uvJtHP59SJpAFmt0o6j5Q4f47UhWcrFq9Dava49/baYRWgcB/IspWZQH4iPxaQagemkL44L4yIP3az3k2kvlgb03nuxyVxFKkP2wGkpol/kpLUv9F9X8ZOIk2Rsw2ps/hBwH+zaNDMi8CWefTk0vApUh+ynUnJzDDSYJ57gCMj4neF8oeQRu/+gHTRfYbUQfxWSR8jzcX336S+bjeQ+gHd3GC/tWbQ/2TRyPKLACLirDzw6RukUeEjSQnHY3n7zzfzwiLiRUl/JCUAT0TE7U2sNpvUR3FnUv+lYaS+mL8nTRfTU43Mf5JqGv4jxy1gg4iYLGl3UkL7ZdJn4m7SF9DhdE4g/5eUyO9POi8GkBKMholLRNwlaTtSMnUEqa/l06Qv7h838bq78uMc41dIA71eJH2BntRFH+L6mFo9J7rS8JzL+/iupLtzfEeSXveLpL7FX21hH11p6X3oSkTMl/Qh0ntzGOl9gpTw/pUmkrWIeFXS+4Gvs+i68wbpGngLjQcFthLjPEkXkpLBGbRwm9GI+IfSXKTHkc6XcaSk6T4azPXapB+RPj+HkxLw50l9zs8i/dhdYhFxkqQZpHPkZNKP2Nr+tiKdq7WyzR733l47rCp8J5pSKZbd3cm6DkJ6CBgYEc3epaWtlObx+w/gZxFRxpehmZl1QdJppAT6zdHcPL5mixm87nqx7le6GyvXdzz1raPujohmpxxsm2U1iKZLudloE9KvyP7iy6QmuK9ImhMRve37Y2a23JM0uNgfWukmBuOAB508Wq+0v76sUtqWQObEcSPSYIKX6P6WgX1K7oD9ufwwM7Ny7KB0f+rLSE3Ro0m3lRxG7wfp2HLOfSDL1c4ayP8ijc5+GPhkLH5bMzMzW/48CTxFShpXIw1iuovUV7H0aZJsOeMEslRtSyAjYod27dvMzPqeiHiSNKODmfVxbe8D2ZeceOKJ/n1iZtaD448/3sNZrX/xND6lcwJZcMuJD7Y7hIXGHp/mnr7jzGltjmSRbQ5PNyq5/ZK+ceevbQ9I0wnecm2n+arbZuzuaZ7u2yb2navVdvuk7/vbrug7t/3d7iNpzvI/3V68FXf77LhtGr9x0187zZXfFjttnWatufK9vZpisVT7/m3FdodgtmT6ziW5EpbqnWjMzMzMrHpcA2lmZmbV5xrIUrkG0szMzCqvdjvDvv5o6rVIB0m6R9JMSf+SdI6kNxfKSNKxkv4paY6kmyVtUdbxdAJpZmZm1k9I+jBwIek+9/uSbo37QeAPkurzum+TbmN6CrAP6TbTN0h6UxlxuAnbzMzMrP84GLgnIr5UW5DvIX8l8HbgEUmDSQnkSRFxei5zOzCZdFvQ7/Q2CCeQZmYVN/32x5h61d3MfvJ5Fsx5nRVGDGHoO9dnjX22Ytgm67U7PLNlozp9IFcEXi0sm57/rU2xtR2wCnBJrUBEzJI0EdgTJ5BmZtadKWdcz0sT/8aqO72L9ffakhVWGcK8F19l2p8f4omjz2GT/zuCQWuPaneYZktXteaB/A1whaRxwBXAm4DvAX+KiIdzmTFAB/BEYd1HgAPLCMIJpJlZRU2//TFeuvKvrH/k3qy26+aLPbfqTu/i1TsfZ8BK/how608i4ipJ44EzgQl58W3Ah+uKjQJmRkRHYfVpwBBJK0VEryZ09iAaM7OKeunKvzHkbWt3Sh5rRrzvbay42vBlHJVZm0Q/ecDqku6qe3yu/mVI2hH4FfBTYEfgIGBV4HJJ9XfVaFTnqm6ea4l/epqZVVB0LGDWo1NYc79t2h2KWd/Qf5qwp0bEVt08/2Pg9xHxrdoCSfcCj5JGZV9GqmkcLmlgoRZyJDA7Inp9eysnkGZmFfTGjNnE/A5WWmOVxZZHBCyo+yYdICTf2tqqTVSqD+QY0jQ+C0XEY5LmABvlRY8CA4GNgccK6z5aRhBOIM3MqqiLL8sXL7uT535z48K/1/3Cbqyxz3uXUVBmVoJngC3rF0h6B7AyaZoeSH0iZwAfJw2wQdIQ0nyQZ5QRhBNIM7MKWmHEELTiQOZPfW2x5avutCnDN1sfgMeOPKsdoZm1R3VqIH8FnCrpOeAaYC3gv0jJ49UAETFX0snAcZKmkWodjyKNfTmtjCCcQJqZVZAGDmDomHWZ8fenWfuw7RcuX3HUMFYcNayNkZm1QbWm8fkZMA/4IvAF0hyQtwDHRMSsunInkxLGY4DVgLuAXSPihTKC8ChsM7OKWmPf9zL7sed45aYH2h2KmZUkkl9GxGYRMTQi1omIAyPi6Qblvh8R60bEyhHxgYj4e1lxuAbSzKyiRm77dtbYd2ueOXUir90/mRFbv5UVVhnCG6/N4bW//wOAAYNXanOUZstIdWog+wQnkGZmFbbu53Zl2KbrMfWqe3j2p1fRMWdeupXhmHXY8MQDGbHVxu0O0WzZcAJZKieQZmYVN3K7MYzcbky7wzBrqwr1gewT3AfSzMzMzFriGkgzMzOrPtdAlsoJpJmZmVXbovtMW0nchG1mZmZmLXENpJmZmVWeB9GUywmkmZmZVZ8TyFI5gSwYe/ym7Q6hk20OH9XuEDrZ9oC+Nfnw2N072h1CJ9vto3aH0Ml2H+l7vVZ23HZuu0PoZKet57Q7hMXs+7cV2x2CWb/nGshy9b1vEzMzMzPr01wDWXD7JfPaHcJCtVq+W64d2OZIFqnV9N16Vd+oXXv/h9JPytsv7UPv2/7pfbvjor5Ts7bNQYMBuOPi19scySLbHDgIgFuv6RvnEsD790zn081/6hs1fh/ccT4A57y9b8QDMO6x+e0OwWzJuAayVE4gzczMrNo8jU/p3IRtZmZmZi1xDaSZmZlVmvLDyuME0szMzKrPTdilchO2mZmZmbXENZBmZmZWeZ4HslxOIM3MzKz6nECWygmkmZmZVZ8TyFK5D6SZmZmZtcQ1kGZmZlZt4T6QZXMCaWZmZtXnBLJUbsI2MzMzs5a4BtLMzMwqz03Y5XICaWZmZtXnBLJUTiDNzMys8lwDWS73gTQzMzOzlrgG0szMzKotcBN2yZxAmpmZWfU5gSyVm7DNzMzMrCWugTQzM7NKEx5EUzYnkGZmZlZ9TiBL5QTSzMzMKk/hDLJM7gNpZmZmZi1xDaSZmZlVm6fxKZ0TSDMzM6s8D6IplxPIgm0PWKndIXQydveOdofQyfs/1Lc+idvu3/fet20OGtzuEDrZ5sBB7Q6hk/fv2bfOJYAP7ji/3SEsZtxjfSseMzMnkGZmZlZ9fe+3ar/mBLLgkjmrtDuEhQ5YeQYAN9w7tM2RLLLLFrMA+PMtfaMma/uxrwNwy7UD2xzJIrUa49v+0OZA6my3d/r39kvmtTeQOrXa/tt/13dq17b92IoA3HHR3DZHktRqsX+z7sptjmSRT0+Z0+4QzJaIm7DL5QTSzMzMqs8JZKk8jY+ZmZmZtcQ1kGZmZlZt4SbssjmBNDMzs+pzAlkqN2GbmZmZWUtcA2lmZmaVJtyEXTbXQJqZmVn1RfSPRxMkrSDp25KekPS6pCmSTi2UkaRjJf1T0hxJN0vaoqzD6RpIzyPRSwAACjxJREFUMzMzq7yK1UCeBewMnAg8CqwHbFIo823gOODoXOYo4AZJm0bE870NwAmkmZmZWT8haQ/gIGDziHi4izKDSQnkSRFxel52OzAZ+BLwnd7G4SZsMzMzq7boR4+efRq4qavkMdsOWAW4ZOEhiJgFTAT2bGovPXACaWZmZpWnBf3j0YT3AY9LOl3SDEmzJV0m6c11ZcYAHcAThXUfyc/1mhNIMzMzs75jdUl31T0+V3j+TcB4YAtSU/angPcAl0tSLjMKmBkRHYV1pwFDJK3U2yDdB9LMzMyqr/8MopkaEVt187zyY9+IeBlA0r+BPwM7ATfmco1esbp5riVOIM3MzKzyKjQKexrwdC15zG4B5pFGYt+YywyXNLBQCzkSmB0R83sbhBNIMzMzq7ag6TkW+4FHgEENlguo9aJ8FBgIbAw8VldmTH6u19wH0szMzKz/+AOwmaTV65Z9EFgRuC//fRswA/h4rYCkIcA+wDVlBOEaSDMzM6u8CjVhnwF8BZgo6QfAcOAU4IaIuAUgIuZKOhk4TtI0Fk0kPgA4rYwgnECamZlZ9VUkgYyIGZJ2An4GXETq+3gl8LVC0ZNJCeMxwGrAXcCuEfFCGXE4gTQzMzPrRyLiSWCvHsoE8P38KJ0TSDMzM6s0Uakm7D7BCaSZmZlVW0SVRmH3CR6FbWZmZmYtcQ2kmZmZVZ6bsMvlBNLMzMyqzwlkqZxAFhyw8ox2h9DJLlvMancInWw/9vV2h7CYsbsX7xffftvt3e4IOtv2gJXaHUIn235sxXaH0Mk2Bw1udwiL+fSUOe0Owazfcw1kudwH0szMzMxa4hrIgnOHDG93CAsdNvu1dodgZn3AJVv0naqTA+5Vu0Mwa10AC/rO56gKnECamZlZ9Tl/LJWbsM3MzMysJa6BNDMzs8rzIJpyOYE0MzOz6vOdaErlBNLMzMwqzzWQ5XIfSDMzMzNriWsgzczMrNoCj8IumRNIMzMzqzQBch/IUrkJ28zMzMxa4hpIMzMzq74F7Q6gWpxAmpmZWeW5CbtcTiDNzMys2jyIpnTuA2lmZmZmLXENpJmZmVVc+E40JXMCaWZmZpXnO9GUy03YZmZmZtYS10CamZlZ9bkJu1ROIM3MzKzaAuR5IEvlBNLMzMyqzzWQpXIfSDMzMzNriWsgzczMrPpcAVkqJ5BmZmZWeb6VYbnchG1mZmZmLXENpJmZmVWfayBL5QSy4LDZr7U7BDOzxRxwr9odgln/FoCn8SmVE0gzMzOrNBHuA1kyJ5AF5w5epd0hLHTY3BkAXPZy34lpv9VSTFc/ObzNkSR7bZxqjC9/qe8co4+ukY7Rpa/2nZj2H5FiOn/FvhPTIfNTTBNG9I1zCeCTr6bz6awNBrU5kuRT/3gdgNt2mNbmSBbZbtKododgZn2AE0gzMzOrPtdAlsoJpJmZmVWfE8hSeRofMzMzM2uJayDNzMys2jwKu3ROIM3MzKzyPAq7XE4gzczMrPqcQJbKfSDNzMzMrCWugTQzM7OKC9dAlswJpJmZmVVb4ASyZG7CNjMzM7OWOIE0MzOz6lvQTx4tkrSOpJmSQtKwuuWSdKykf0qaI+lmSVu0vofG3IRtZmZmlVfhaXx+BMwEhhaWfxs4DjgaeBQ4CrhB0qYR8Xxvd+oaSDMzM7N+SNIHgD2A/yksH0xKIE+KiNMj4gbg46TeoF8qY99OIM3MzKz6IvrHo0mSBgKnAd+F/9/e/YZWVcdxHP/8Nuf0bu2/2ijLwEAqE8KKDGpSTpNmFCGUWs7IygcV+SCKbAyVJKjAEkyYLSgl8UEihFQPpD9EYA96EP3FsIxQ19zmZubcvj04y8274TzeY7/z5/2Cy7bfudx9drfBh9/vnN9RR97heZIqJO0a/vGtT9JeSfcU/F6KAgkAANLOJA1aMh4X7klJkyRtGePYLEkDkn7OG/9+6FjBOAcSAACkXKL2gaxzzh0Y8fU2M9s28gnOuVpJ6yUtN7N+51z+a1RL6jWzgbzx45JyzrmJZna6kJAUSAAAgPjoMLO54zxno6Svzeyj8zxnrMbsznMsFAokAABIv+TMQJ6Xc+56Sask3eGcqxoazg19rHTODSiYabzMOVecNwtZJemkmfUXmoMCCQAA0i8lBVLStZJKJH01xrHDktok7ZBULGmmpB9HHJ+lYEufglEgAQAAkuMLSfPzxhZJel7SYkkHJR2S1KNg654NkuScy0lqkrRNEaBAAgCAdPvvKuwUMLMOSftHjjnnZgx9+rmZ9Q6NbZK0zjl3XMMbiRcp2PqnYBRIAACQcibZRdwnMNk2KSiML0iqlXRA0gIzOxLFi1MgAQBA+qXnHMhRzKxdUnvemCm4WnvjpfiebCQOAACAUJiBBAAA6ZaicyDjggKZZ8WpHt8RRnmgNn6ZFs884TvCOe6fEr/36MHK+GVa1h+/TI92x+tvSZKaf/3Hd4RzzNtf7TsCkHwpXsL2gSVsAAAAhMIMZJ79X07yHeGshttPSZI++bbMc5JhC+b0SZL2/FnhOUngvvpgRm3dE+97TjJs/dvLJEnbr8iN88z/z6o/TkqS3psYj9+bJC0/Hfzudv0dn0xLJweZdg7GI9NDRUGe9ppyz0mGrezs9R0BuDjMQEaKAgkAAFLOKJARo0ACAIB0M0mDmdsH8pLiHEgAAACEwgwkAABIP5awI0WBROa1f9CjLW1d+ungaU2Y4DRjeoka5k3Wa61TfEcDAESFAhkplrCRaZs2d2r12iNqbMhpd1u92jdP05KFZdr7cZ/vaAAAxBYzkMi0Le90afWKSm18se7sWFNjuV5eW+MxFQAgWsadaCJGgUSmdXUP6vIpxaPGnXMe0gAALgmTzLgKO0oUSGTaTbNL9db2bk2/skT33l2m2prRZRIAkALMQEaKcyCRaW++MlXlZU6rnjmiaTcc1Ow7D6nl1b/Uc2LAdzQAAGKLAolMu/G6Un332dX68N16PbWyUmbShjc6dcui39Xbx3IHAKSGWTIeCcESNjKvtLRITY3lamoM7jfctqNbq9ce1fYd3Xr68WrP6QAABTPjTjQRYwYSyPPYw5WqqS7SD7/0+44CAEAsMQOJTDvacUZT6879NzjWcUbdPYOaNsbV2QCAhErQ8nASUCCRaXPm/6YlC8u0oCGnqbUTdOhwv17fely5yUV6ZGmF73gAgIgYS9iRokAi09Y9V6M9+/r07EvH1NkV7Al5282TtHNrva65qsR3PABAJJJ1gUoSUCCRaWuaq7Smucp3DAAAEoUCCQAA0s3ERuIRo0ACAID041aGkWIbHwAAAITCDCQAAEg1k2QsYUeKAgkAANLNjCXsiFEgAQBA6jEDGS3OgQQAAEAozthY86zW1lbeDAAYR0tLi/OdAQijwtXYre4u3zEuyKe2+xszm+s7x3gokAAAINWcc/sk1fnOcYE6zGyR7xDjoUACAAAgFM6BBAAAQCgUSAAAAIRCgQQAAEAoFEgAAACEQoEEAABAKP8CnSUoKohlE6sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "plot_state_visitations(dataq, ['Dyna-Q : State visitations before the env changes', 'Dyna-Q : State visitations after the env changes'], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0979f12aeeebfa64035c9f27fc407d97",
          "grade": false,
          "grade_id": "cell-50778038da2d7233",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "q9_tC6WAOTaF"
      },
      "source": [
        "What do you observe?\n",
        "\n",
        "The state visitation map looks almost the same before and after the shortcut opens. This means that the Dyna-Q agent hasn't quite discovered and started exploiting the new shortcut.\n",
        "\n",
        "Now let's try increasing the exploration parameter $\\epsilon$ to see if it helps the Dyna-Q agent discover the shortcut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c2dcbc40b05319c4b4efc75ae0128e4d",
          "grade": false,
          "grade_id": "cell-27a96a3ebc8bd13a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ukhCfFUkOTaG"
      },
      "outputs": [],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "def run_experiment_only_cumulative_reward(env, agent, env_parameters, agent_parameters, exp_parameters):\n",
        "\n",
        "    # Experiment settings\n",
        "    num_runs = exp_parameters['num_runs']\n",
        "    num_max_steps = exp_parameters['num_max_steps']\n",
        "    epsilons = agent_parameters['epsilons']\n",
        "\n",
        "    env_info = {\"change_at_n\" : env_parameters[\"change_at_n\"]}\n",
        "    agent_info = {\"num_states\" : agent_parameters[\"num_states\"],\n",
        "                  \"num_actions\" : agent_parameters[\"num_actions\"],\n",
        "                  \"planning_steps\": agent_parameters[\"planning_steps\"],\n",
        "                  \"discount\": env_parameters[\"discount\"],\n",
        "                  \"step_size\" : agent_parameters[\"step_size\"]}\n",
        "\n",
        "    log_data = {'epsilons' : epsilons}\n",
        "    cum_reward_all = np.zeros((len(epsilons), num_runs, num_max_steps))\n",
        "\n",
        "    for eps_idx, epsilon in enumerate(epsilons):\n",
        "\n",
        "        print('Agent : Dyna-Q, epsilon : %f' % epsilon)\n",
        "        os.system('sleep 1')          # to prevent tqdm printing out-of-order before the above print()\n",
        "        agent_info[\"epsilon\"] = epsilon\n",
        "\n",
        "        for run in tqdm(range(num_runs)):\n",
        "\n",
        "            agent_info['random_seed'] = run\n",
        "            agent_info['planning_random_seed'] = run\n",
        "\n",
        "            rl_glue = RLGlue(env, agent)  # Creates a new RLGlue experiment with the env and agent we chose above\n",
        "            rl_glue.rl_init(agent_info, env_info) # We pass RLGlue what it needs to initialize the agent and environment\n",
        "\n",
        "            num_steps = 0\n",
        "            cum_reward = 0\n",
        "\n",
        "            while num_steps < num_max_steps-1 :\n",
        "\n",
        "                rl_glue.rl_start()  # We start the experiment\n",
        "                is_terminal = False\n",
        "\n",
        "                while not is_terminal and num_steps < num_max_steps-1 :\n",
        "                    reward, _, action, is_terminal = rl_glue.rl_step()  # The environment and agent take a step and return\n",
        "                    # the reward, and action taken.\n",
        "                    num_steps += 1\n",
        "                    cum_reward += reward\n",
        "                    cum_reward_all[eps_idx][run][num_steps] = cum_reward\n",
        "\n",
        "    log_data['cum_reward_all'] = cum_reward_all\n",
        "    return log_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "35b1244013e6641a28af6ee1c5e19020",
          "grade": false,
          "grade_id": "cell-7e4c0e42c445b2dc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XgDyuIkbOTaG",
        "outputId": "ef22bdc4-0d95-40f8-fcff-cfc3da6929d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent : Dyna-Q, epsilon : 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:48<00:00,  1.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent : Dyna-Q, epsilon : 0.200000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:49<00:00,  1.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent : Dyna-Q, epsilon : 0.400000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:48<00:00,  1.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent : Dyna-Q, epsilon : 0.800000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:47<00:00,  1.59s/it]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"num_runs\" : 30,                     # The number of times we run the experiment\n",
        "    \"num_max_steps\" : 6000,              # The number of steps per experiment\n",
        "}\n",
        "\n",
        "# Environment parameters\n",
        "environment_parameters = {\n",
        "    \"discount\": 0.95,\n",
        "    \"change_at_n\": 3000\n",
        "}\n",
        "\n",
        "# Agent parameters\n",
        "agent_parameters = {\n",
        "    \"num_states\" : 54,\n",
        "    \"num_actions\" : 4,\n",
        "    \"step_size\" : 0.125,\n",
        "    \"planning_steps\" : 10,\n",
        "    \"epsilons\": [0.1, 0.2, 0.4, 0.8]    # The list of epsilons we want to try\n",
        "}\n",
        "\n",
        "current_env = ShortcutMazeEnvironment   # The environment\n",
        "current_agent = DynaQAgent              # The agent\n",
        "\n",
        "data = run_experiment_only_cumulative_reward(current_env, current_agent, environment_parameters, agent_parameters, experiment_parameters)\n",
        "plot_cumulative_reward(data, 'epsilons', 'cum_reward_all', 'Cumulative\\nreward', r'$\\epsilon$ = ', r'Dyna-Q : Varying $\\epsilon$')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3e41acbeb9782671cdca735c33cf9b16",
          "grade": false,
          "grade_id": "cell-8159dc6c61e345f9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "kH-ZCSYxOTaG"
      },
      "source": [
        "What do you observe?\n",
        "\n",
        "Increasing the exploration via the $\\epsilon$-greedy strategy does not seem to be helping. In fact, the agent's cumulative reward decreases because it is spending more and more time trying out the exploratory actions.\n",
        "\n",
        "Can we do better...?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "88675c8ce603f560311089a74104f394",
          "grade": false,
          "grade_id": "cell-62df4f966a370995",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0jSOoFpBOTaH"
      },
      "source": [
        "## Section 2: Dyna-Q+"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "15faa0c27e0b1427655f666914540c23",
          "grade": false,
          "grade_id": "cell-7961458a916a28a8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JcTzIY9iOTaH"
      },
      "source": [
        "The motivation behind Dyna-Q+ is to give a bonus reward for actions that haven't been tried for a long time, since there is a greater chance that the dynamics for that actions might have changed.\n",
        "\n",
        "In particular, if the modeled reward for a transition is $r$, and the transition has not been tried in $\\tau(s,a)$ time steps, then planning updates are done as if that transition produced a reward of $r + \\kappa \\sqrt{ \\tau(s,a)}$, for some small $\\kappa$.\n",
        "\n",
        "Let's implement that!\n",
        "\n",
        "Based on your `DynaQAgent`, create a new class `DynaQPlusAgent` to implement the aforementioned exploration heuristic. Additionally :\n",
        "1. actions that had never been tried before from a state should now be allowed to be considered in the planning step,\n",
        "2. and the initial model for such actions is that they lead back to the same state with a reward of zero.\n",
        "\n",
        "At this point, you might want to refer to the video lectures and [Section 8.3](http://www.incompleteideas.net/book/RLbook2018.pdf#page=188) of the RL textbook for a refresher on Dyna-Q+."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fc1df956ada702fea2fdd43be25d2144",
          "grade": false,
          "grade_id": "cell-5cb32fc5b37ad166",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wJz_iCFrOTaH"
      },
      "source": [
        "As usual, let's break this down in pieces and do it one-by-one.\n",
        "\n",
        "First of all, check out the `agent_init` method below. In particular, pay attention to the attributes which are new to `DynaQPlusAgent`â€“ state-visitation counts $\\tau$ and the scaling parameter $\\kappa$ â€“ because you shall be using them later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f941a227e6e8174f497769e87d5968b5",
          "grade": false,
          "grade_id": "cell-539ab8af016fc473",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "LrPGgVkTOTaH"
      },
      "outputs": [],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "class DynaQPlusAgent(BaseAgent):\n",
        "\n",
        "    def agent_init(self, agent_info):\n",
        "        \"\"\"Setup for the agent called when the experiment first starts.\n",
        "\n",
        "        Args:\n",
        "            agent_init_info (dict), the parameters used to initialize the agent. The dictionary contains:\n",
        "            {\n",
        "                num_states (int): The number of states,\n",
        "                num_actions (int): The number of actions,\n",
        "                epsilon (float): The parameter for epsilon-greedy exploration,\n",
        "                step_size (float): The step-size,\n",
        "                discount (float): The discount factor,\n",
        "                planning_steps (int): The number of planning steps per environmental interaction\n",
        "                kappa (float): The scaling factor for the reward bonus\n",
        "\n",
        "                random_seed (int): the seed for the RNG used in epsilon-greedy\n",
        "                planning_random_seed (int): the seed for the RNG used in the planner\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        # First, we get the relevant information from agent_info\n",
        "        # Note: we use np.random.RandomState(seed) to set the two different RNGs\n",
        "        # for the planner and the rest of the code\n",
        "        try:\n",
        "            self.num_states = agent_info[\"num_states\"]\n",
        "            self.num_actions = agent_info[\"num_actions\"]\n",
        "        except:\n",
        "            print(\"You need to pass both 'num_states' and 'num_actions' \\\n",
        "                   in agent_info to initialize the action-value table\")\n",
        "        self.gamma = agent_info.get(\"discount\", 0.95)\n",
        "        self.step_size = agent_info.get(\"step_size\", 0.1)\n",
        "        self.epsilon = agent_info.get(\"epsilon\", 0.1)\n",
        "        self.planning_steps = agent_info.get(\"planning_steps\", 10)\n",
        "        self.kappa = agent_info.get(\"kappa\", 0.001)\n",
        "\n",
        "        self.rand_generator = np.random.RandomState(agent_info.get('random_seed', 42))\n",
        "        self.planning_rand_generator = np.random.RandomState(agent_info.get('planning_random_seed', 42))\n",
        "\n",
        "        # Next, we initialize the attributes required by the agent, e.g., q_values, model, tau, etc.\n",
        "        # The visitation-counts can be stored as a table as well, like the action values\n",
        "        self.q_values = np.zeros((self.num_states, self.num_actions))\n",
        "        self.tau = np.zeros((self.num_states, self.num_actions))\n",
        "        self.actions = list(range(self.num_actions))\n",
        "        self.past_action = -1\n",
        "        self.past_state = -1\n",
        "        self.model = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1a7b620740e82640f572213177bee2ef",
          "grade": false,
          "grade_id": "cell-1cad0227d9ff16d5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Xip-S0qFOTaH"
      },
      "source": [
        "Now first up, implement the `update_model` method. Note that this is different from Dyna-Q in the aforementioned way.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ff36e4ae144e4409bd1ea34b1918000f",
          "grade": false,
          "grade_id": "cell-d4452e4cd395456a",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "vBSnBy4qOTaH"
      },
      "outputs": [],
      "source": [
        "%%add_to DynaQPlusAgent\n",
        "\n",
        "# -----------\n",
        "# Graded Cell\n",
        "# -----------\n",
        "\n",
        "def update_model(self, past_state, past_action, state, reward):\n",
        "    \"\"\"updates the model\n",
        "\n",
        "    Args:\n",
        "        past_state  (int): s\n",
        "        past_action (int): a\n",
        "        state       (int): s'\n",
        "        reward      (int): r\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    # Recall that when adding a state-action to the model, if the agent is visiting the state\n",
        "    #    for the first time, then the remaining actions need to be added to the model as well\n",
        "    #    with zero reward and a transition into itself.\n",
        "    #\n",
        "    # Note: do *not* update the visitation-counts here. We will do that in `agent_step`.\n",
        "    #\n",
        "    # (3 lines)\n",
        "\n",
        "    if past_state not in self.model:\n",
        "        self.model[past_state] = {past_action : (state, reward)}\n",
        "        # ----------------\n",
        "        # your code here\n",
        "        for action in range(self.num_actions):\n",
        "            if action != past_action:\n",
        "                self.model[past_state][action] = (past_state, 0)\n",
        "        # ----------------\n",
        "    else:\n",
        "        self.model[past_state][past_action] = (state, reward)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a9c44b9a6b276c0e08312dec0d413076",
          "grade": false,
          "grade_id": "cell-a44ec8b7ac701e0c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "-xj_JDl9OTaH"
      },
      "source": [
        "### Test `update_model()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fc850bdd9ff71c46e5e9b7246c7625d4",
          "grade": true,
          "grade_id": "cell-8cdef71644d2952f",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "l7guI35mOTaH"
      },
      "outputs": [],
      "source": [
        "# -----------\n",
        "# Tested Cell\n",
        "# -----------\n",
        "# The contents of the cell will be tested by the autograder.\n",
        "# If they do not pass here, they will not pass there.\n",
        "\n",
        "actions = []\n",
        "agent_info = {\"num_actions\": 4,\n",
        "              \"num_states\": 3,\n",
        "              \"epsilon\": 0.1,\n",
        "              \"step_size\": 0.1,\n",
        "              \"discount\": 1.0,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 0}\n",
        "\n",
        "agent = DynaQPlusAgent()\n",
        "agent.agent_init(agent_info)\n",
        "\n",
        "agent.update_model(0,2,0,1)\n",
        "agent.update_model(2,0,1,1)\n",
        "agent.update_model(0,3,1,2)\n",
        "agent.tau[0][0] += 1\n",
        "\n",
        "expected_model = {\n",
        "    0: {\n",
        "        0: (0, 0),\n",
        "        1: (0, 0),\n",
        "        2: (0, 1),\n",
        "        3: (1, 2),\n",
        "    },\n",
        "    2: {\n",
        "        0: (1, 1),\n",
        "        1: (2, 0),\n",
        "        2: (2, 0),\n",
        "        3: (2, 0),\n",
        "    },\n",
        "}\n",
        "assert agent.model == expected_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9c1771a9ba649fde3e588bae3022e161",
          "grade": false,
          "grade_id": "cell-885fe1cd5447e0b0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Hl223agROTaH"
      },
      "source": [
        "Next, you will implement the `planning_step()` method. This will be very similar to the one you implemented in `DynaQAgent`, but here you will be adding the exploration bonus to the reward in the simulated transition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6ef80ec707602f554d0a56412d066855",
          "grade": false,
          "grade_id": "cell-b3605364bf724124",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "4NfKrAH_OTaI"
      },
      "outputs": [],
      "source": [
        "%%add_to DynaQPlusAgent\n",
        "\n",
        "# -----------\n",
        "# Graded Cell\n",
        "# -----------\n",
        "\n",
        "def planning_step(self):\n",
        "    \"\"\"performs planning, i.e. indirect RL.\n",
        "\n",
        "    Args:\n",
        "        None\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    # The indirect RL step:\n",
        "    # - Choose a state and action from the set of experiences that are stored in the model. (~2 lines)\n",
        "    # - Query the model with this state-action pair for the predicted next state and reward.(~1 line)\n",
        "    # - **Add the bonus to the reward** (~1 line)\n",
        "    # - Update the action values with this simulated experience.                            (2~4 lines)\n",
        "    # - Repeat for the required number of planning steps.\n",
        "    #\n",
        "    # Note that the update equation is different for terminal and non-terminal transitions.\n",
        "    # To differentiate between a terminal and a non-terminal next state, assume that the model stores\n",
        "    # the terminal state as a dummy state like -1\n",
        "    #\n",
        "    # Important: remember you have a random number generator 'planning_rand_generator' as\n",
        "    #     a part of the class which you need to use as self.planning_rand_generator.choice()\n",
        "    #     For the sake of reproducibility and grading, *do not* use anything else like\n",
        "    #     np.random.choice() for performing search control.\n",
        "\n",
        "    # ----------------\n",
        "    # your code here\n",
        "    keys = list(self.model.keys())\n",
        "    for _ in range(self.planning_steps):\n",
        "        s = self.planning_rand_generator.choice(keys)\n",
        "\n",
        "        state = self.model[s]\n",
        "\n",
        "        actions = list(state)\n",
        "        a = self.planning_rand_generator.choice(actions)\n",
        "        (new_state, reward) = self.model[s][a]\n",
        "        error =  0.0\n",
        "        bonus = self.kappa * np.sqrt(self.tau[s,a])\n",
        "        if new_state == -1:\n",
        "            #terminal stage\n",
        "            error = self.step_size * (reward + 0 + bonus  - self.q_values[s][a])\n",
        "        else:\n",
        "\n",
        "            error = self.step_size * (reward + self.gamma * np.max(self.q_values[new_state]) + bonus - self.q_values[s][a])\n",
        "            #print(\"bonus\",bonus)\n",
        "        self.q_values[s][a] = self.q_values[s][a] + error\n",
        "        #print(\"values\",self.q_values)\n",
        "    # ----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4d4d85edc08c8307d5a7072c79c30aad",
          "grade": false,
          "grade_id": "cell-0df5e5a11dce577b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Rm6bcnKUOTaI"
      },
      "source": [
        "### Test `planning_step()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "506a78d3a89c1a04c8f59e6a69515623",
          "grade": true,
          "grade_id": "cell-1bae4d3c34b953a2",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "GCSesdOAOTaI"
      },
      "outputs": [],
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for planning_step() ##\n",
        "\n",
        "actions = []\n",
        "agent_info = {\"num_actions\": 4,\n",
        "              \"num_states\": 3,\n",
        "              \"epsilon\": 0.1,\n",
        "              \"step_size\": 0.1,\n",
        "              \"discount\": 1.0,\n",
        "              \"kappa\": 0.001,\n",
        "              \"planning_steps\": 4,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 1}\n",
        "\n",
        "agent = DynaQPlusAgent()\n",
        "agent.agent_init(agent_info)\n",
        "\n",
        "agent.update_model(0,1,-1,1)\n",
        "agent.tau += 1\n",
        "agent.tau[0][1] = 0\n",
        "\n",
        "agent.update_model(0,2,1,1)\n",
        "agent.tau += 1\n",
        "agent.tau[0][2] = 0\n",
        "\n",
        "agent.update_model(2,0,1,1)\n",
        "agent.tau += 1\n",
        "agent.tau[2][0] = 0\n",
        "\n",
        "agent.planning_step()\n",
        "\n",
        "expected_model = {\n",
        "    0: {\n",
        "        1: (-1, 1),\n",
        "        0: (0, 0),\n",
        "        2: (1, 1),\n",
        "        3: (0, 0),\n",
        "    },\n",
        "    2: {\n",
        "        0: (1, 1),\n",
        "        1: (2, 0),\n",
        "        2: (2, 0),\n",
        "        3: (2, 0),\n",
        "    },\n",
        "}\n",
        "assert agent.model == expected_model\n",
        "\n",
        "expected_values = np.array([\n",
        "    [0, 0.10014142, 0, 0],\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0.00036373, 0, 0.00017321],\n",
        "])\n",
        "assert np.allclose(agent.q_values, expected_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0463f44477f43a3e5ac587a664caf3e9",
          "grade": false,
          "grade_id": "cell-49b8bb85128d50f3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "hYrwgLiMOTaI"
      },
      "source": [
        "Again, before you move on to implement the rest of the agent methods, here are the couple of helper functions that you've used in the previous assessments for choosing an action using an $\\epsilon$-greedy policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "81bcd74d211cf70c7259d7e035ed6393",
          "grade": false,
          "grade_id": "cell-0550ca807b59d14c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "S2f06HNLOTaI"
      },
      "outputs": [],
      "source": [
        "%%add_to DynaQPlusAgent\n",
        "\n",
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "def argmax(self, q_values):\n",
        "    \"\"\"argmax with random tie-breaking\n",
        "    Args:\n",
        "        q_values (Numpy array): the array of action values\n",
        "    Returns:\n",
        "        action (int): an action with the highest value\n",
        "    \"\"\"\n",
        "    top = float(\"-inf\")\n",
        "    ties = []\n",
        "\n",
        "    for i in range(len(q_values)):\n",
        "        if q_values[i] > top:\n",
        "            top = q_values[i]\n",
        "            ties = []\n",
        "\n",
        "        if q_values[i] == top:\n",
        "            ties.append(i)\n",
        "\n",
        "    return self.rand_generator.choice(ties)\n",
        "\n",
        "def choose_action_egreedy(self, state):\n",
        "    \"\"\"returns an action using an epsilon-greedy policy w.r.t. the current action-value function.\n",
        "\n",
        "    Important: assume you have a random number generator 'rand_generator' as a part of the class\n",
        "                which you can use as self.rand_generator.choice() or self.rand_generator.rand()\n",
        "\n",
        "    Args:\n",
        "        state (List): coordinates of the agent (two elements)\n",
        "    Returns:\n",
        "        The action taken w.r.t. the aforementioned epsilon-greedy policy\n",
        "    \"\"\"\n",
        "\n",
        "    if self.rand_generator.rand() < self.epsilon:\n",
        "        action = self.rand_generator.choice(self.actions)\n",
        "    else:\n",
        "        values = self.q_values[state]\n",
        "        action = self.argmax(values)\n",
        "\n",
        "    return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cfc05c6dac5be58f8070c05bcab23dc4",
          "grade": false,
          "grade_id": "cell-ff89fce4c62dd24b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "CsxH2D9SOTaI"
      },
      "source": [
        "Now implement the rest of the agent-related methods, namely `agent_start`, `agent_step`, and `agent_end`. Again, these will be very similar to the ones in the `DynaQAgent`, but you will have to think of a way to update the counts since the last visit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9ea6edbc6526bfb8d57d8d6a03514ba1",
          "grade": false,
          "grade_id": "cell-675ebe1d175f5730",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Y4-R61gTOTaI"
      },
      "outputs": [],
      "source": [
        "%%add_to DynaQPlusAgent\n",
        "\n",
        "# -----------\n",
        "# Graded Cell\n",
        "# -----------\n",
        "\n",
        "def agent_start(self, state):\n",
        "    \"\"\"The first method called when the experiment starts, called after\n",
        "    the environment starts.\n",
        "    Args:\n",
        "        state (Numpy array): the state from the\n",
        "            environment's env_start function.\n",
        "    Returns:\n",
        "        (int) The first action the agent takes.\n",
        "    \"\"\"\n",
        "\n",
        "    # given the state, select the action using self.choose_action_egreedy(),\n",
        "    # and save current state and action (~2 lines)\n",
        "    ### self.past_state = ?\n",
        "    ### self.past_action = ?\n",
        "    # Note that the last-visit counts are not updated here.\n",
        "\n",
        "    # ----------------\n",
        "    # your code here\n",
        "    self.past_state = state\n",
        "    self.past_action = self.choose_action_egreedy(state)\n",
        "    # ----------------\n",
        "\n",
        "    return self.past_action\n",
        "\n",
        "def agent_step(self, reward, state):\n",
        "    \"\"\"A step taken by the agent.\n",
        "    Args:\n",
        "        reward (float): the reward received for taking the last action taken\n",
        "        state (Numpy array): the state from the\n",
        "            environment's step based on where the agent ended up after the\n",
        "            last step\n",
        "    Returns:\n",
        "        (int) The action the agent is taking.\n",
        "    \"\"\"\n",
        "\n",
        "    # Update the last-visited counts (~2 lines)\n",
        "    # - Direct-RL step (1~3 lines)\n",
        "    # - Model Update step (~1 line)\n",
        "    # - `planning_step` (~1 line)\n",
        "    # - Action Selection step (~1 line)\n",
        "    # Save the current state and action before returning the action to be performed. (~2 lines)\n",
        "\n",
        "    # ----------------\n",
        "    # your code here\n",
        "    #calculate previous state value\n",
        "    q_s_a = self.q_values[self.past_state][self.past_action]\n",
        "    error = self.step_size* (reward + self.gamma * np.max(self.q_values[state])  - q_s_a)\n",
        "\n",
        "    for state_id, actions in enumerate(self.tau):\n",
        "        for action_id, action in enumerate(actions):\n",
        "            if state_id == self.past_state and action_id == self.past_action:\n",
        "                self.tau[state_id,action_id] = 0\n",
        "            else:\n",
        "                self.tau[state_id,action_id] = action + 1\n",
        "    #print(f\"state: {self.past_state},action: {self.past_action}, tau: {self.tau}\")\n",
        "\n",
        "    #update previous state/action value\n",
        "    self.q_values[self.past_state][self.past_action] = error\n",
        "    #update model (past_state, past_action, state, reward)\n",
        "    self.update_model(self.past_state, self.past_action, state, reward)\n",
        "    #planning\n",
        "    self.planning_step()\n",
        "    #select next action\n",
        "    self.past_action = self.choose_action_egreedy(state)\n",
        "    self.past_state = state\n",
        "\n",
        "    # ----------------\n",
        "\n",
        "    return self.past_action\n",
        "\n",
        "def agent_end(self, reward):\n",
        "    \"\"\"Called when the agent terminates.\n",
        "    Args:\n",
        "        reward (float): the reward the agent received for entering the\n",
        "            terminal state.\n",
        "    \"\"\"\n",
        "    # Again, add the same components you added in agent_step to augment Dyna-Q into Dyna-Q+\n",
        "\n",
        "    # ----------------\n",
        "    # your code here\n",
        "\n",
        "    for state_id, actions in enumerate(self.tau):\n",
        "        for action_id, action in enumerate(actions):\n",
        "            if state_id == self.past_state and action_id == self.past_action:\n",
        "                self.tau[state_id,action_id] = 0\n",
        "            else:\n",
        "                self.tau[state_id,action_id] = action + 1\n",
        "    #print(f\"self.tau: {self.tau}\")\n",
        "    #calculate previous state value\n",
        "    q_s_a = self.q_values[self.past_state][self.past_action]\n",
        "    #print(\"q_s_a\",q_s_a)\n",
        "    error = self.step_size* (reward + 0  - q_s_a)\n",
        "\n",
        "    #update previous state/action value\n",
        "    self.q_values[self.past_state][self.past_action] = error\n",
        "\n",
        "    #update model\n",
        "    self.update_model(self.past_state, self.past_action, -1, reward)\n",
        "    #planning\n",
        "    self.planning_step()\n",
        "    # ----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "375c9af20c23fbafe952776276d580dd",
          "grade": false,
          "grade_id": "cell-05300ec8845616b2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9RL3KA9lOTaJ"
      },
      "source": [
        "### Test `agent_start()`, `agent_step()`, and `agent_end()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "44a3a0b6fcb2e7f37c933bd18ff378f8",
          "grade": true,
          "grade_id": "cell-9cf838836ad39efb",
          "locked": true,
          "points": 15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WaixOcUGOTaJ"
      },
      "outputs": [],
      "source": [
        "# -----------\n",
        "# Tested Cell\n",
        "# -----------\n",
        "# The contents of the cell will be tested by the autograder.\n",
        "# If they do not pass here, they will not pass there.\n",
        "\n",
        "agent_info = {\"num_actions\": 4,\n",
        "              \"num_states\": 3,\n",
        "              \"epsilon\": 0.1,\n",
        "              \"step_size\": 0.1,\n",
        "              \"discount\": 1.0,\n",
        "              \"kappa\": 0.001,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_steps\": 4,\n",
        "              \"planning_random_seed\": 0}\n",
        "\n",
        "agent = DynaQPlusAgent()\n",
        "agent.agent_init(agent_info)\n",
        "\n",
        "action = agent.agent_start(0) # state\n",
        "assert action == 1\n",
        "\n",
        "assert np.allclose(agent.tau, 0)\n",
        "assert np.allclose(agent.q_values, 0)\n",
        "assert agent.model == {}\n",
        "\n",
        "# ---------------\n",
        "# test agent step\n",
        "# ---------------\n",
        "\n",
        "action = agent.agent_step(1, 2)\n",
        "assert action == 3\n",
        "\n",
        "action = agent.agent_step(0, 1)\n",
        "assert action == 1\n",
        "\n",
        "expected_tau = np.array([\n",
        "    [2, 1, 2, 2],\n",
        "    [2, 2, 2, 2],\n",
        "    [2, 2, 2, 0],\n",
        "])\n",
        "assert np.all(agent.tau == expected_tau)\n",
        "\n",
        "expected_values = np.array([\n",
        "    [0.0191, 0.271, 0.0, 0.0191],\n",
        "    [0, 0, 0, 0],\n",
        "    [0, 0.000183847763, 0.000424264069, 0],\n",
        "])\n",
        "assert np.allclose(agent.q_values, expected_values)\n",
        "\n",
        "expected_model = {\n",
        "    0: {\n",
        "        1: (2, 1),\n",
        "        0: (0, 0),\n",
        "        2: (0, 0),\n",
        "        3: (0, 0),\n",
        "    },\n",
        "    2: {\n",
        "        3: (1, 0),\n",
        "        0: (2, 0),\n",
        "        1: (2, 0),\n",
        "        2: (2, 0),\n",
        "    },\n",
        "}\n",
        "assert agent.model == expected_model\n",
        "\n",
        "# --------------\n",
        "# test agent end\n",
        "# --------------\n",
        "agent.agent_end(1)\n",
        "\n",
        "expected_tau = np.array([\n",
        "    [3, 2, 3, 3],\n",
        "    [3, 0, 3, 3],\n",
        "    [3, 3, 3, 1],\n",
        "])\n",
        "assert np.all(agent.tau == expected_tau)\n",
        "\n",
        "expected_values = np.array([\n",
        "    [0.0191, 0.344083848, 0, 0.0444632051],\n",
        "    [0.0191732051, 0.19, 0, 0],\n",
        "    [0, 0.000183847763, 0.000424264069, 0],\n",
        "])\n",
        "assert np.allclose(agent.q_values, expected_values)\n",
        "\n",
        "expected_model = {0: {1: (2, 1), 0: (0, 0), 2: (0, 0), 3: (0, 0)}, 2: {3: (1, 0), 0: (2, 0), 1: (2, 0), 2: (2, 0)}, 1: {1: (-1, 1), 0: (1, 0), 2: (1, 0), 3: (1, 0)}}\n",
        "assert agent.model == expected_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "79c71f3b2858306fde14049a0383667f",
          "grade": false,
          "grade_id": "cell-0e614343c0d86b2d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4VEHq1nXOTaJ"
      },
      "source": [
        "### Experiment: Dyna-Q+ agent in the _changing_ environment\n",
        "\n",
        "Okay, now we're ready to test our Dyna-Q+ agent on the Shortcut Maze. As usual, we will average the results over 30 independent runs of the experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b694d2c1d02154058ad127123594b44",
          "grade": false,
          "grade_id": "cell-22a658123d08fafa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HluAS6mLOTaJ",
        "outputId": "2076a1ad-8161-44a5-b960-9f0d734993a3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'run_experiment_with_state_visitations' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-5576258e7b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mcurrent_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDynaQPlusAgent\u001b[0m          \u001b[0;31m# The agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdata_qplus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment_with_state_visitations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dyna-Q+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'run_experiment_with_state_visitations' is not defined"
          ]
        }
      ],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"num_runs\" : 30,                     # The number of times we run the experiment\n",
        "    \"num_max_steps\" : 6000,              # The number of steps per experiment\n",
        "}\n",
        "\n",
        "# Environment parameters\n",
        "environment_parameters = {\n",
        "    \"discount\": 0.95,\n",
        "    \"change_at_n\": 3000\n",
        "}\n",
        "\n",
        "# Agent parameters\n",
        "agent_parameters = {\n",
        "    \"num_states\" : 54,\n",
        "    \"num_actions\" : 4,\n",
        "    \"epsilon\": 0.1,\n",
        "    \"step_size\" : 0.5,\n",
        "    \"planning_steps\" : [50]\n",
        "}\n",
        "\n",
        "current_env = ShortcutMazeEnvironment   # The environment\n",
        "current_agent = DynaQPlusAgent          # The agent\n",
        "\n",
        "data_qplus = run_experiment_with_state_visitations(current_env, current_agent, environment_parameters, agent_parameters, experiment_parameters, \"Dyna-Q+\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3c8507e67b844c085afe5bd111f176cc",
          "grade": false,
          "grade_id": "cell-5d80afb4585b0357",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "YGqxsUTEOTaJ"
      },
      "source": [
        "Let's compare the Dyna-Q and Dyna-Q+ agents with `planning_steps=50` each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "56f9182c13c40b6647f53e95d2a89302",
          "grade": false,
          "grade_id": "cell-b17bc044f6e4e020",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zrJOSLstOTaJ"
      },
      "outputs": [],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "def plot_cumulative_reward_comparison(data1, data2):\n",
        "\n",
        "    cum_reward_q = data1['cum_reward_all'][2]\n",
        "    cum_reward_qPlus = data2['cum_reward_all'][0]\n",
        "\n",
        "    plt.plot(np.mean(cum_reward_qPlus, axis=0), label='Dyna-Q+')\n",
        "    plt.plot(np.mean(cum_reward_q, axis=0), label='Dyna-Q')\n",
        "\n",
        "    plt.axvline(x=3000, linestyle='--', color='grey', alpha=0.4)\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel('Cumulative\\nreward', rotation=0, labelpad=60)\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title('Average performance of Dyna-Q and Dyna-Q+ agents in the Shortcut Maze\\n')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "74b2b53a88c98b3a41f4ccdf24c585bf",
          "grade": false,
          "grade_id": "cell-bff6a7315a81ba36",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "paXs2LcjOTaJ"
      },
      "outputs": [],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "plot_cumulative_reward_comparison(dataq, data_qplus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "74108cc11abe9d0edcfd58957ecd5cf1",
          "grade": false,
          "grade_id": "cell-3b4406fd8796da4e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "LtLkRx5VOTaJ"
      },
      "source": [
        "What do you observe? (For reference, your graph should look like [Figure 8.5 in Chapter 8](http://www.incompleteideas.net/book/RLbook2018.pdf#page=189) of the RL textbook)\n",
        "\n",
        "The slope of the curve increases for the Dyna-Q+ curve shortly after the shortcut opens up after 3000 steps, which indicates that the rate of receiving the positive reward increases. This implies that the Dyna-Q+ agent finds the shorter path to the goal.\n",
        "\n",
        "To verify this, let us plot the state-visitations of the Dyna-Q+ agent before and after the shortcut opens up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "02a92b5dfca164799531bfbfc51b2947",
          "grade": false,
          "grade_id": "cell-30b40e125c10f4a1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "44a8LqBCOTaJ"
      },
      "outputs": [],
      "source": [
        "# ---------------\n",
        "# Discussion Cell\n",
        "# ---------------\n",
        "\n",
        "plot_state_visitations(data_qplus, ['Dyna-Q+ : State visitations before the env changes', 'Dyna-Q+ : State visitations after the env changes'], 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "93e6b7711fe3bbb622a649369171566d",
          "grade": false,
          "grade_id": "cell-c2e1a4549783e5d9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a2MwuotHOTaJ"
      },
      "source": [
        "What do you observe?\n",
        "\n",
        "Before the shortcut opens up, like Dyna-Q, the Dyna-Q+ agent finds the sole, long path to the goal. But because the Dyna-Q+ agent keeps exploring, it succeeds in discovering the shortcut once it opens up, which leads to the goal faster. So the bonus reward heuristic is effective in helping the agent explore and find changes in the environment without degrading the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "316c6bb4a3a11821d48d0c4482b546b4",
          "grade": false,
          "grade_id": "cell-122b7fbe5a69ce76",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "G0jKUs9sOTaK"
      },
      "source": [
        "## Wrapping Up\n",
        "\n",
        "Congratulations! You have:\n",
        "\n",
        "1. implemented Dyna-Q, a model-based approach to RL;\n",
        "2. implemented Dyna-Q+, a variant of Dyna-Q with an exploration bonus that encourages exploration;\n",
        "3. conducted scientific experiments to empirically validate the exploration/exploitation dilemma in the planning context on an environment that changes with time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "af62c782e534d54888e892bb8588ad60",
          "grade": false,
          "grade_id": "cell-38d472ccebc0dd45",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "RQGndmSaOTaK"
      },
      "source": [
        "Some points to ponder about:\n",
        "1. At what cost does Dyna-Q+ improve over Dyna-Q?\n",
        "2. In general, what is the trade-off of using model-based methods like Dyna-Q over model-free methods like Q-learning?\n"
      ]
    }
  ],
  "metadata": {
    "coursera": {
      "course_slug": "sample-based-learning-methods",
      "graded_item_id": "trR7Z",
      "launcher_item_id": "edrCE"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}